{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "129c9abd",
   "metadata": {},
   "source": [
    "### Description\n",
    "\n",
    "The notebook provides different NLP similarity pipelines, evaluated on public STS dataset.\n",
    "\n",
    "The notebook details functions for preprocessing text and calculating similarities through cosine similarity. Various embedding strategies are explored, including weighted, string-level, distributed and contexual across different preprocessing techniques. It assesses model performance using pearson and spearson coorelation score, presenting comparative results to determine the most effective methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a635baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "\n",
    "import math\n",
    "import scipy\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import gc\n",
    "\n",
    "from transformers import BertTokenizer, BertModel, RobertaTokenizer, RobertaModel\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67f924f",
   "metadata": {},
   "source": [
    "### Section 0: Load & Preprocess STS Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ac5e541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the 'stsb_multi_mt' dataset specifically for the English language ('en')\n",
    "# 'stsb_multi_mt' refers to the multilingual STS benchmark dataset which includes various translations\n",
    "# The 'name=\"en\"' parameter specifies that we are interested in the English portion of this dataset\n",
    "# This dataset is used for evaluating semantic textual similarity models\n",
    "\n",
    "dataset = load_dataset(\"stsb_multi_mt\", name = \"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bc5c41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sts_train = dataset['train'].to_pandas()\n",
    "sts_test = dataset['test'].to_pandas()\n",
    "sts_dev = dataset['dev'].to_pandas()\n",
    "\n",
    "sts_dev_test = pd.concat([sts_dev, sts_test], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb562277",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_updated_df(df):\n",
    "    \n",
    "    char_count_columns = df[['sentence1', 'sentence2']].astype(str).applymap(len)\n",
    "    df = df[char_count_columns.gt(30).all(axis=1)]\n",
    "    return df\n",
    "\n",
    "def format_float(x):\n",
    "    if isinstance(x, float):\n",
    "        if x.is_integer():\n",
    "            return x\n",
    "        else:\n",
    "            return float(\"{:.2f}\".format(x))\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2684957",
   "metadata": {},
   "outputs": [],
   "source": [
    "sts_dev_test_updated = get_updated_df(sts_dev_test)\n",
    "sts_train_updated = get_updated_df(sts_train)\n",
    "\n",
    "sts_dev_test_updated['similarity_score'] = sts_dev_test_updated['similarity_score'].apply(format_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e52975c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A man with a hard hat is dancing.</td>\n",
       "      <td>A man wearing a hard hat is dancing.</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A man is feeding a mouse to a snake.</td>\n",
       "      <td>The man is feeding a mouse to the snake.</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A man is erasing a chalk board.</td>\n",
       "      <td>The man is erasing the chalk board.</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>The man cut down a tree with an axe.</td>\n",
       "      <td>A man chops down a tree with an axe.</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>The girl sang into a microphone.</td>\n",
       "      <td>The lady sang into the microphone.</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               sentence1  \\\n",
       "0      A man with a hard hat is dancing.   \n",
       "2   A man is feeding a mouse to a snake.   \n",
       "6        A man is erasing a chalk board.   \n",
       "13  The man cut down a tree with an axe.   \n",
       "16      The girl sang into a microphone.   \n",
       "\n",
       "                                   sentence2  similarity_score  \n",
       "0       A man wearing a hard hat is dancing.               5.0  \n",
       "2   The man is feeding a mouse to the snake.               5.0  \n",
       "6        The man is erasing the chalk board.               5.0  \n",
       "13      A man chops down a tree with an axe.               5.0  \n",
       "16        The lady sang into the microphone.               2.4  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sts_dev_test_updated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e84decfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessing:\n",
    "    def __init__(self):\n",
    "        \n",
    "        # Initialize the Preprocessing class with a lemmatizer and a set of English stop words\n",
    "        \n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    def rm_specialchars(self, text):\n",
    "\n",
    "        line = re.sub(r\"http\\S+\", \"\", text)\n",
    "        line = re.sub(\"[^A-Za-z]+\", \" \", line)\n",
    "        line = re.sub('\\s+', ' ', line)\n",
    "        line = line.replace('\\t',' ')\n",
    "        line = line.replace('\\n',' ')\n",
    "        line = line.replace('\\r',' ')\n",
    "        line = line.replace(',',' ')\n",
    "        line = line.replace('-',' ')\n",
    "        return line.strip()\n",
    "\n",
    "\n",
    "    def rm_stopwords(self, text):\n",
    "\n",
    "        word_tokens = word_tokenize(text)\n",
    "        filtered_text = [word for word in word_tokens if word not in self.stop_words]\n",
    "        return ' '.join(filtered_text)\n",
    "\n",
    "\n",
    "    def lemmatize_str(self, text):\n",
    "        \n",
    "        lemma_text = [self.lemmatizer.lemmatize(word) for word in text]\n",
    "        return (''.join(lemma_text)).strip()\n",
    "    \n",
    "\n",
    "    def lowercase_str(self, text):\n",
    "        \n",
    "        return text.lower()\n",
    "\n",
    "\n",
    "    def basic_preprocess(self, text):\n",
    "        \"\"\"\n",
    "        Perform a basic preprocessing routine on the input text:\n",
    "        Lowercase the string, remove special characters, and lemmatize the result.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        l_str = self.lowercase_str(text)\n",
    "        sc_str = self.rm_specialchars(l_str)\n",
    "        updated_text = self.lemmatize_str(sc_str)\n",
    "        \n",
    "        return updated_text\n",
    "    \n",
    "    def preprocess(self, text):\n",
    "        \"\"\"\n",
    "        Perform a comprehensive preprocessing routine on the input text:\n",
    "        Lowercase the string, remove special characters and stopwords, and lemmatize the result.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        l_str = self.lowercase_str(text)\n",
    "        sc_str = self.rm_specialchars(l_str)\n",
    "        sw_str = self.rm_stopwords(sc_str)\n",
    "        updated_text = self.lemmatize_str(sw_str)\n",
    "        \n",
    "        return updated_text\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5adadbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = Preprocessing()\n",
    "\n",
    "def apply_preprocessing(preprocessor, df):\n",
    "    \n",
    "    df['b_sentence1'] = df['sentence1'].apply(lambda x: preprocessor.basic_preprocess(x))\n",
    "    df['b_sentence2'] = df['sentence2'].apply(lambda x: preprocessor.basic_preprocess(x))\n",
    "    \n",
    "    df['p_sentence1'] = df['sentence1'].apply(lambda x: preprocessor.preprocess(x))\n",
    "    df['p_sentence2'] = df['sentence2'].apply(lambda x: preprocessor.preprocess(x))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11a57098",
   "metadata": {},
   "outputs": [],
   "source": [
    "sts_train_updated = apply_preprocessing(preprocessor, sts_train_updated)\n",
    "sts_dev_test_updated = apply_preprocessing(preprocessor, sts_dev_test_updated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bc768ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>similarity_score</th>\n",
       "      <th>b_sentence1</th>\n",
       "      <th>b_sentence2</th>\n",
       "      <th>p_sentence1</th>\n",
       "      <th>p_sentence2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A man with a hard hat is dancing.</td>\n",
       "      <td>A man wearing a hard hat is dancing.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>a man with a hard hat is dancing</td>\n",
       "      <td>a man wearing a hard hat is dancing</td>\n",
       "      <td>man hard hat dancing</td>\n",
       "      <td>man wearing hard hat dancing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A man is feeding a mouse to a snake.</td>\n",
       "      <td>The man is feeding a mouse to the snake.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>a man is feeding a mouse to a snake</td>\n",
       "      <td>the man is feeding a mouse to the snake</td>\n",
       "      <td>man feeding mouse snake</td>\n",
       "      <td>man feeding mouse snake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A man is erasing a chalk board.</td>\n",
       "      <td>The man is erasing the chalk board.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>a man is erasing a chalk board</td>\n",
       "      <td>the man is erasing the chalk board</td>\n",
       "      <td>man erasing chalk board</td>\n",
       "      <td>man erasing chalk board</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>The man cut down a tree with an axe.</td>\n",
       "      <td>A man chops down a tree with an axe.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>the man cut down a tree with an axe</td>\n",
       "      <td>a man chops down a tree with an axe</td>\n",
       "      <td>man cut tree axe</td>\n",
       "      <td>man chops tree axe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>The girl sang into a microphone.</td>\n",
       "      <td>The lady sang into the microphone.</td>\n",
       "      <td>2.4</td>\n",
       "      <td>the girl sang into a microphone</td>\n",
       "      <td>the lady sang into the microphone</td>\n",
       "      <td>girl sang microphone</td>\n",
       "      <td>lady sang microphone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               sentence1  \\\n",
       "0      A man with a hard hat is dancing.   \n",
       "2   A man is feeding a mouse to a snake.   \n",
       "6        A man is erasing a chalk board.   \n",
       "13  The man cut down a tree with an axe.   \n",
       "16      The girl sang into a microphone.   \n",
       "\n",
       "                                   sentence2  similarity_score  \\\n",
       "0       A man wearing a hard hat is dancing.               5.0   \n",
       "2   The man is feeding a mouse to the snake.               5.0   \n",
       "6        The man is erasing the chalk board.               5.0   \n",
       "13      A man chops down a tree with an axe.               5.0   \n",
       "16        The lady sang into the microphone.               2.4   \n",
       "\n",
       "                            b_sentence1  \\\n",
       "0      a man with a hard hat is dancing   \n",
       "2   a man is feeding a mouse to a snake   \n",
       "6        a man is erasing a chalk board   \n",
       "13  the man cut down a tree with an axe   \n",
       "16      the girl sang into a microphone   \n",
       "\n",
       "                                b_sentence2              p_sentence1  \\\n",
       "0       a man wearing a hard hat is dancing     man hard hat dancing   \n",
       "2   the man is feeding a mouse to the snake  man feeding mouse snake   \n",
       "6        the man is erasing the chalk board  man erasing chalk board   \n",
       "13      a man chops down a tree with an axe         man cut tree axe   \n",
       "16        the lady sang into the microphone     girl sang microphone   \n",
       "\n",
       "                     p_sentence2  \n",
       "0   man wearing hard hat dancing  \n",
       "2        man feeding mouse snake  \n",
       "6        man erasing chalk board  \n",
       "13            man chops tree axe  \n",
       "16          lady sang microphone  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sts_dev_test_updated.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842e43ca",
   "metadata": {},
   "source": [
    "### Util Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2b4bb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_corr_values(dictionary):\n",
    "    \n",
    "    modified_dict = {key: float(format(value, \".4e\")) if 'e' in str(value) else float(format(value, \".4f\")) \n",
    "                     for key, value in dictionary.items()}\n",
    "    \n",
    "    return modified_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f622d965",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pearson_spearman_results(sts_pearson_corr, b_pearson_corr, p_pearson_corr,\n",
    "                                 sts_spearmanr_corr, b_spearmanr_corr, p_spearmanr_corr):\n",
    "    \n",
    "    # Define a dictionary to store Pearson and Spearman correlation results for \n",
    "    #three different preprocessing stages\n",
    "\n",
    "    corr_results = {\n",
    "        \"Pearson\": {\n",
    "            \"sts\": {\n",
    "                \"r\": sts_pearson_corr.correlation,\n",
    "                \"pvalue\":sts_pearson_corr.pvalue\n",
    "                \n",
    "            },\n",
    "            \"basic_sts\": {\n",
    "                \"r\": b_pearson_corr.correlation,\n",
    "                \"pvalue\": b_pearson_corr.pvalue\n",
    "                \n",
    "\n",
    "            },\n",
    "            \"preprocess_sts\": {\n",
    "                \"r\": p_pearson_corr.correlation,\n",
    "                \"pvalue\":p_pearson_corr.pvalue\n",
    " \n",
    "            },\n",
    "        },\n",
    "        \"Spearman\": {\n",
    "            \"sts\": {\n",
    "                \"r\": sts_spearmanr_corr.correlation,\n",
    "                \"pvalue\": sts_spearmanr_corr.pvalue,\n",
    "                \n",
    "            },\n",
    "            \"basic_sts\": {\n",
    "                \"r\": b_spearmanr_corr.correlation,\n",
    "                \"pvalue\": b_spearmanr_corr.pvalue,\n",
    "\n",
    "            },\n",
    "            \"preprocess_sts\": {\n",
    "                \"r\": p_spearmanr_corr.correlation,\n",
    "                \"pvalue\": p_spearmanr_corr.pvalue,\n",
    "\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    #  Convert the nested dictionary into a DataFrame for better readability and further analysis\n",
    "\n",
    "    corr_results_df = pd.DataFrame.from_dict(corr_results)\n",
    "    \n",
    "    \n",
    "    corr_results_df['Pearson'] = corr_results_df['Pearson'].apply(format_corr_values)\n",
    "    corr_results_df['Spearman'] = corr_results_df['Spearman'].apply(format_corr_values) \n",
    "\n",
    "    return corr_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c110e4d2",
   "metadata": {},
   "source": [
    "### Section 1: Weighted Representation Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80da7b78",
   "metadata": {},
   "source": [
    "#### 1.1 tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6e3edc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectorizer(text_preprocessed):\n",
    "    \n",
    "    if text_preprocessed:\n",
    "        vectorizer = TfidfVectorizer(min_df=3, max_df=0.5, \n",
    "                                     ngram_range=(1,3), \n",
    "                                     stop_words=None)\n",
    "\n",
    "        \n",
    "    else:\n",
    "        vectorizer = TfidfVectorizer(min_df=3, max_df=0.5, \n",
    "                                     ngram_range=(1,3), \n",
    "                                     lowercase=False,\n",
    "                                     stop_words=None) \n",
    " \n",
    "    return vectorizer\n",
    "\n",
    "\n",
    "def get_train_vecs(df_train, columnA, columnB):\n",
    "        \n",
    "    train_sents = df_train[[columnA, columnB]].values.tolist()\n",
    "    train_sents = [item for sublist in train_sents for item in sublist]\n",
    "\n",
    "    return train_sents\n",
    "\n",
    "\n",
    "def get_tfidf_results(df_train, df_test, columnA, columnB, score_column,\n",
    "                      text_preprocessed):\n",
    "    \n",
    "    train_sents = get_train_vecs(df_train, columnA, columnB)\n",
    "    vectorizer = get_vectorizer(text_preprocessed)\n",
    "    vectorizer.fit_transform(train_sents)\n",
    "    \n",
    "    list1 = vectorizer.transform(df_test[columnA].tolist())\n",
    "    list2 = normalize(list1.toarray())\n",
    "    \n",
    "    list2 = vectorizer.transform(df_test[columnB].tolist())\n",
    "    list2 = normalize(list2.toarray())\n",
    "    \n",
    "    sims_scores = cosine_similarity(list1, list2)\n",
    "    tfidf_scores = list(np.diagonal(sims_scores))\n",
    "    tfidf_scores = [float(\"{:.2f}\".format(i)) for i in tfidf_scores]\n",
    "    \n",
    "    df_test[score_column] = tfidf_scores\n",
    "    \n",
    "    sts_scores = df_test['similarity_score'].tolist()\n",
    "        \n",
    "    pearson_corr = scipy.stats.pearsonr(tfidf_scores, sts_scores)\n",
    "    spearmanr_corr = scipy.stats.spearmanr(tfidf_scores, sts_scores)\n",
    "\n",
    "    return df_test, pearson_corr, spearmanr_corr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9432b1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_train_df = sts_train_updated.copy()\n",
    "tfidf_test_df = sts_dev_test_updated.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bea3f80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tfidf, pearsonr, spearmanr = get_tfidf_results(tfidf_train_df, tfidf_test_df,\n",
    "                                                 'sentence1', 'sentence2', \n",
    "                                                 'sts_tfidf_score', \n",
    "                                                 text_preprocessed=False)\n",
    "\n",
    "df_tfidf, b_pearson, b_spearmanr = get_tfidf_results(tfidf_train_df, tfidf_test_df,\n",
    "                                                     'b_sentence1', 'b_sentence2', \n",
    "                                                     'b_sts_tfidf_score', \n",
    "                                                     text_preprocessed=True)\n",
    "\n",
    "\n",
    "df_tfidf, p_pearson, p_spearmanr = get_tfidf_results(tfidf_train_df, tfidf_test_df,\n",
    "                                                     'p_sentence1', 'p_sentence2', \n",
    "                                                     'p_sts_tfidf_score',\n",
    "                                                     text_preprocessed=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b919c647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pearson</th>\n",
       "      <th>Spearman</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sts</th>\n",
       "      <td>{'r': 0.5901, 'pvalue': 4.5673e-204}</td>\n",
       "      <td>{'r': 0.5918, 'pvalue': 1.5367e-205}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>basic_sts</th>\n",
       "      <td>{'r': 0.6142, 'pvalue': 1.6358e-225}</td>\n",
       "      <td>{'r': 0.6148, 'pvalue': 4.5898e-226}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preprocess_sts</th>\n",
       "      <td>{'r': 0.6423, 'pvalue': 4.031e-253}</td>\n",
       "      <td>{'r': 0.635, 'pvalue': 1.1265e-245}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Pearson  \\\n",
       "sts             {'r': 0.5901, 'pvalue': 4.5673e-204}   \n",
       "basic_sts       {'r': 0.6142, 'pvalue': 1.6358e-225}   \n",
       "preprocess_sts   {'r': 0.6423, 'pvalue': 4.031e-253}   \n",
       "\n",
       "                                            Spearman  \n",
       "sts             {'r': 0.5918, 'pvalue': 1.5367e-205}  \n",
       "basic_sts       {'r': 0.6148, 'pvalue': 4.5898e-226}  \n",
       "preprocess_sts   {'r': 0.635, 'pvalue': 1.1265e-245}  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_corr_results = get_pearson_spearman_results(pearsonr, b_pearson, p_pearson,\n",
    "                                                  spearmanr, b_spearmanr, p_spearmanr)\n",
    "tfidf_corr_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d9971830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>similarity_score</th>\n",
       "      <th>b_sentence1</th>\n",
       "      <th>b_sentence2</th>\n",
       "      <th>p_sentence1</th>\n",
       "      <th>p_sentence2</th>\n",
       "      <th>sts_tfidf_score</th>\n",
       "      <th>b_sts_tfidf_score</th>\n",
       "      <th>p_sts_tfidf_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A man with a hard hat is dancing.</td>\n",
       "      <td>A man wearing a hard hat is dancing.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>a man with a hard hat is dancing</td>\n",
       "      <td>a man wearing a hard hat is dancing</td>\n",
       "      <td>man hard hat dancing</td>\n",
       "      <td>man wearing hard hat dancing</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A man is feeding a mouse to a snake.</td>\n",
       "      <td>The man is feeding a mouse to the snake.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>a man is feeding a mouse to a snake</td>\n",
       "      <td>the man is feeding a mouse to the snake</td>\n",
       "      <td>man feeding mouse snake</td>\n",
       "      <td>man feeding mouse snake</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A man is erasing a chalk board.</td>\n",
       "      <td>The man is erasing the chalk board.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>a man is erasing a chalk board</td>\n",
       "      <td>the man is erasing the chalk board</td>\n",
       "      <td>man erasing chalk board</td>\n",
       "      <td>man erasing chalk board</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.69</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>The man cut down a tree with an axe.</td>\n",
       "      <td>A man chops down a tree with an axe.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>the man cut down a tree with an axe</td>\n",
       "      <td>a man chops down a tree with an axe</td>\n",
       "      <td>man cut tree axe</td>\n",
       "      <td>man chops tree axe</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>The girl sang into a microphone.</td>\n",
       "      <td>The lady sang into the microphone.</td>\n",
       "      <td>2.4</td>\n",
       "      <td>the girl sang into a microphone</td>\n",
       "      <td>the lady sang into the microphone</td>\n",
       "      <td>girl sang microphone</td>\n",
       "      <td>lady sang microphone</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               sentence1  \\\n",
       "0      A man with a hard hat is dancing.   \n",
       "2   A man is feeding a mouse to a snake.   \n",
       "6        A man is erasing a chalk board.   \n",
       "13  The man cut down a tree with an axe.   \n",
       "16      The girl sang into a microphone.   \n",
       "\n",
       "                                   sentence2  similarity_score  \\\n",
       "0       A man wearing a hard hat is dancing.               5.0   \n",
       "2   The man is feeding a mouse to the snake.               5.0   \n",
       "6        The man is erasing the chalk board.               5.0   \n",
       "13      A man chops down a tree with an axe.               5.0   \n",
       "16        The lady sang into the microphone.               2.4   \n",
       "\n",
       "                            b_sentence1  \\\n",
       "0      a man with a hard hat is dancing   \n",
       "2   a man is feeding a mouse to a snake   \n",
       "6        a man is erasing a chalk board   \n",
       "13  the man cut down a tree with an axe   \n",
       "16      the girl sang into a microphone   \n",
       "\n",
       "                                b_sentence2              p_sentence1  \\\n",
       "0       a man wearing a hard hat is dancing     man hard hat dancing   \n",
       "2   the man is feeding a mouse to the snake  man feeding mouse snake   \n",
       "6        the man is erasing the chalk board  man erasing chalk board   \n",
       "13      a man chops down a tree with an axe         man cut tree axe   \n",
       "16        the lady sang into the microphone     girl sang microphone   \n",
       "\n",
       "                     p_sentence2  sts_tfidf_score  b_sts_tfidf_score  \\\n",
       "0   man wearing hard hat dancing             0.76               0.76   \n",
       "2        man feeding mouse snake             0.82               0.82   \n",
       "6        man erasing chalk board             0.70               0.69   \n",
       "13            man chops tree axe             0.86               0.87   \n",
       "16          lady sang microphone             0.32               0.32   \n",
       "\n",
       "    p_sts_tfidf_score  \n",
       "0                0.82  \n",
       "2                1.00  \n",
       "6                1.00  \n",
       "13               0.87  \n",
       "16               0.59  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33922222",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tfidf.to_csv('./results/STS_results/TFIDF/tfidf_sts_results.csv', index=False)\n",
    "tfidf_corr_results.to_csv('./results/STS_results/TFIDF/tfidf_sts_corr_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28928601",
   "metadata": {},
   "source": [
    "### Section 2: String-Level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5301f28e",
   "metadata": {},
   "source": [
    "#### 2.1 JSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf133514",
   "metadata": {},
   "outputs": [],
   "source": [
    "jsi_df = sts_dev_test_updated.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b33b54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(sentence1, sentence2):\n",
    "    \n",
    "    tokens1 = set(sentence1.split())\n",
    "    tokens2 = set(sentence2.split())\n",
    "    intersection = len(tokens1.intersection(tokens2))    \n",
    "    return float(intersection) / (len(tokens1) + len(tokens2) - intersection)\n",
    "\n",
    "def find_highest_jsi(df, result_column, columnA, columnB):\n",
    "\n",
    "    jsi_results = []\n",
    "    ref_sent1 = df[columnA].tolist()\n",
    "    ref_sent2 = df[columnB].tolist()\n",
    "    \n",
    "    for sent1, sent2 in zip(ref_sent1, ref_sent2):\n",
    "        \n",
    "        jsi_score = jaccard_similarity(sent1, sent2)\n",
    "        jsi_results.append(float(\"{:.2f}\".format(jsi_score)))\n",
    "    \n",
    "    df[result_column] = jsi_results\n",
    "\n",
    "    sts_scores = df['similarity_score'].tolist()\n",
    "    \n",
    "    pearson_corr = scipy.stats.pearsonr(jsi_results, sts_scores)\n",
    "    spearmanr_corr = scipy.stats.spearmanr(jsi_results, sts_scores)\n",
    "          \n",
    "    return df, pearson_corr, spearmanr_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac557c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "jsi_df, pearsonr, spearmanr = find_highest_jsi(jsi_df, 'sts_jsi_score',\n",
    "                                               'sentence1', 'sentence2')\n",
    "\n",
    "jsi_df, b_pearson, b_spearmanr = find_highest_jsi(jsi_df, 'b_sts_jsi_score',\n",
    "                                                  'b_sentence1', 'b_sentence2')\n",
    "\n",
    "jsi_df, p_pearson, p_spearmanr = find_highest_jsi(jsi_df, 'p_sts_jsi_score',\n",
    "                                                  'p_sentence1', 'p_sentence2')\n",
    "jsi_corr_results = get_pearson_spearman_results(pearsonr, b_pearson, p_pearson,\n",
    "                                                spearmanr, b_spearmanr, p_spearmanr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "51fc22b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pearson</th>\n",
       "      <th>Spearman</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sts</th>\n",
       "      <td>{'r': 0.5679, 'pvalue': 8.554e-186}</td>\n",
       "      <td>{'r': 0.5757, 'pvalue': 4.7407e-192}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>basic_sts</th>\n",
       "      <td>{'r': 0.6493, 'pvalue': 2.2982e-260}</td>\n",
       "      <td>{'r': 0.6557, 'pvalue': 2.7874e-267}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preprocess_sts</th>\n",
       "      <td>{'r': 0.6982, 'pvalue': 1.8116e-317}</td>\n",
       "      <td>{'r': 0.7076, 'pvalue': 0.0}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Pearson  \\\n",
       "sts              {'r': 0.5679, 'pvalue': 8.554e-186}   \n",
       "basic_sts       {'r': 0.6493, 'pvalue': 2.2982e-260}   \n",
       "preprocess_sts  {'r': 0.6982, 'pvalue': 1.8116e-317}   \n",
       "\n",
       "                                            Spearman  \n",
       "sts             {'r': 0.5757, 'pvalue': 4.7407e-192}  \n",
       "basic_sts       {'r': 0.6557, 'pvalue': 2.7874e-267}  \n",
       "preprocess_sts          {'r': 0.7076, 'pvalue': 0.0}  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsi_corr_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed179274",
   "metadata": {},
   "outputs": [],
   "source": [
    "jsi_df.to_csv('./results/STS_results/JSI/JSI_sts_results.csv', \n",
    "              index=False)\n",
    "\n",
    "jsi_corr_results.to_csv('./results/STS_results/JSI/JSI_sts_corr_results.csv', \n",
    "                        index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf2bcc9",
   "metadata": {},
   "source": [
    "### Section 3: Distributed Representation Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021ce99b",
   "metadata": {},
   "source": [
    "#### 3.1 Glove Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be873db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "glove_model_url = 'https://nlp.stanford.edu/data/glove.6B.zip'\n",
    "save_dir = './models/glove_model'\n",
    "\n",
    "response = requests.get(glove_model_url)\n",
    "\n",
    "zip_file_path = os.path.join(save_dir, 'glove.6B.zip')\n",
    "\n",
    "with open(zip_file_path, 'wb') as f:\n",
    "    f.write(response.content)\n",
    "\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall('./models/glove_model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e358e483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000 words loaded!\n"
     ]
    }
   ],
   "source": [
    "def load_glove_model(File):\n",
    "    \n",
    "    glove_model = {}\n",
    "    \n",
    "    with open(File,'r') as f:\n",
    "        for line in f:\n",
    "            split_line = line.split()\n",
    "            word = split_line[0]\n",
    "            embedding = np.array(split_line[1:], dtype=np.float64)\n",
    "            glove_model[word] = embedding\n",
    "    \n",
    "    print(f\"{len(glove_model)} words loaded!\")\n",
    "    return glove_model\n",
    "\n",
    "glove_model = load_glove_model('./models/glove_model/glove.6B.300d.txt')\n",
    "glove_vocab = list(glove_model.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "11f1bd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2vec_similarity(df, result_column, columnA, columnB, \n",
    "                        glove_model, glove_vocab, preprocessor):\n",
    "    \n",
    "\n",
    "    ref_sent1 = df[columnA].tolist()\n",
    "    ref_sent2 = df[columnB].tolist()\n",
    "    \n",
    "    if result_column == 'sts_word2vec_score':\n",
    "            # special case where original sentences needs to be lower cased because the loaded \n",
    "            #glove model is pretrained on lowercase corpus\n",
    "        ref_sent1 = [preprocessor.lowercase_str(x) for x in ref_sent1]\n",
    "        ref_sent2 = [preprocessor.lowercase_str(x) for x in ref_sent2]\n",
    "\n",
    "    \n",
    "    glove_embeds1 = [[glove_model[word] for word in sentence.split() if word in glove_vocab] \n",
    "                     for sentence in ref_sent1]\n",
    "    \n",
    "    glove_embeds2 = [[glove_model[word] for word in sentence.split() if word in glove_vocab] \n",
    "                     for sentence in ref_sent2]\n",
    "\n",
    "    sent_vec1 = [np.mean(normalize(wordvec, axis=1), axis=0) for wordvec in glove_embeds1]\n",
    "    sent_vec2 = [np.mean(normalize(wordvec, axis=1), axis=0) for wordvec in glove_embeds2]\n",
    "    \n",
    "    word2vec_scores = list(np.diagonal(cosine_similarity(sent_vec1, sent_vec2)))\n",
    "    word2vec_scores = [float(\"{:.2f}\".format(i)) for i in word2vec_scores]\n",
    "    \n",
    "    df[result_column] = word2vec_scores\n",
    "    \n",
    "    sts_scores = df['similarity_score'].tolist()\n",
    "        \n",
    "    pearson_corr = scipy.stats.pearsonr(word2vec_scores, sts_scores)\n",
    "    spearmanr_corr = scipy.stats.spearmanr(word2vec_scores, sts_scores)\n",
    "    \n",
    "    return df, pearson_corr, spearmanr_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "18cb87a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_glove_df = sts_dev_test_updated.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6bcefacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_glove_df, pearsonr, spearmanr = word2vec_similarity(word2vec_glove_df, 'sts_word2vec_score',\n",
    "                                                        'sentence1', 'sentence2',  \n",
    "                                                        glove_model, glove_vocab, preprocessor)\n",
    "\n",
    "word2vec_glove_df, b_pearson, b_spearmanr = word2vec_similarity(word2vec_glove_df, 'b_sts_word2vec_score',\n",
    "                                                           'b_sentence1', 'b_sentence2', \n",
    "                                                           glove_model, glove_vocab, preprocessor)\n",
    "\n",
    "word2vec_glove_df, p_pearson, p_spearmanr = word2vec_similarity(word2vec_glove_df, 'p_sts_word2vec_score',\n",
    "                                                           'p_sentence1', 'p_sentence2', \n",
    "                                                           glove_model, glove_vocab, preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7dc07008",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_glove_corr_results = get_pearson_spearman_results(pearsonr, b_pearson, p_pearson,\n",
    "                                                           spearmanr, b_spearmanr, p_spearmanr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1cf313bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pearson</th>\n",
       "      <th>Spearman</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sts</th>\n",
       "      <td>{'r': 0.4006, 'pvalue': 1.4899e-84}</td>\n",
       "      <td>{'r': 0.445, 'pvalue': 3.438e-106}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>basic_sts</th>\n",
       "      <td>{'r': 0.4769, 'pvalue': 7.9044e-124}</td>\n",
       "      <td>{'r': 0.5178, 'pvalue': 2.4746e-149}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preprocess_sts</th>\n",
       "      <td>{'r': 0.6636, 'pvalue': 5.4339e-276}</td>\n",
       "      <td>{'r': 0.6653, 'pvalue': 7.1907e-278}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Pearson  \\\n",
       "sts              {'r': 0.4006, 'pvalue': 1.4899e-84}   \n",
       "basic_sts       {'r': 0.4769, 'pvalue': 7.9044e-124}   \n",
       "preprocess_sts  {'r': 0.6636, 'pvalue': 5.4339e-276}   \n",
       "\n",
       "                                            Spearman  \n",
       "sts               {'r': 0.445, 'pvalue': 3.438e-106}  \n",
       "basic_sts       {'r': 0.5178, 'pvalue': 2.4746e-149}  \n",
       "preprocess_sts  {'r': 0.6653, 'pvalue': 7.1907e-278}  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_glove_corr_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "be0ebd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_glove_df.to_csv('./results/STS_results/Glove_word2vec/word2vec_sts_results.csv', \n",
    "                         index=False)\n",
    "word2vec_glove_corr_results.to_csv('./results/STS_results/Glove_word2vec/word2vec_sts_corr_results.csv', \n",
    "                                   index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5c9a9d",
   "metadata": {},
   "source": [
    "#### 3.2 FastText Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "26d04a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download ft model\n",
    "\n",
    "#import fasttext.util\n",
    "#import shutil\n",
    "\n",
    "#fasttext.util.download_model('en', if_exists='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7fe27f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "ft = fasttext.load_model('./models/cc.en.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d085cd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fasttext_similarity(df, result_column, columnA, columnB, ft):\n",
    "    \n",
    "    ref_sent1 = df[columnA].tolist()\n",
    "    ref_sent2 = df[columnB].tolist()\n",
    "\n",
    "    ft_embeds1 = [ft.get_sentence_vector(sent) for sent in ref_sent1]    \n",
    "    ft_embeds2 = [ft.get_sentence_vector(sent) for sent in ref_sent2]    \n",
    "    \n",
    "    ft_scores = list(np.diagonal(cosine_similarity(ft_embeds1, ft_embeds2)))\n",
    "    ft_scores = [float(\"{:.2f}\".format(i)) for i in ft_scores]\n",
    "    \n",
    "    df[result_column] = ft_scores\n",
    "    sts_scores = df['similarity_score'].tolist()\n",
    "        \n",
    "    pearson_corr = scipy.stats.pearsonr(ft_scores, sts_scores)\n",
    "    spearmanr_corr = scipy.stats.spearmanr(ft_scores, sts_scores)\n",
    "    \n",
    "    return df, pearson_corr, spearmanr_corr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "40cd3c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_df = sts_dev_test_updated.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "56c62af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_df, pearsonr, spearmanr = fasttext_similarity(ft_df, 'sts_ft_score',\n",
    "                                                        'sentence1', 'sentence2', ft)\n",
    "\n",
    "ft_df, b_pearson, b_spearmanr = fasttext_similarity(ft_df, 'b_ft_score',\n",
    "                                                           'b_sentence1', 'b_sentence2', ft)\n",
    "\n",
    "ft_df, p_pearson, p_spearmanr = fasttext_similarity(ft_df, 'p_sts_ft_score',\n",
    "                                                           'p_sentence1', 'p_sentence2', ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ab33e020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pearson</th>\n",
       "      <th>Spearman</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sts</th>\n",
       "      <td>{'r': 0.472, 'pvalue': 5.6961e-121}</td>\n",
       "      <td>{'r': 0.4871, 'pvalue': 7.2688e-130}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>basic_sts</th>\n",
       "      <td>{'r': 0.5367, 'pvalue': 2.1036e-162}</td>\n",
       "      <td>{'r': 0.5486, 'pvalue': 5.4266e-171}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preprocess_sts</th>\n",
       "      <td>{'r': 0.7133, 'pvalue': 0.0}</td>\n",
       "      <td>{'r': 0.7064, 'pvalue': 0.0}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Pearson  \\\n",
       "sts              {'r': 0.472, 'pvalue': 5.6961e-121}   \n",
       "basic_sts       {'r': 0.5367, 'pvalue': 2.1036e-162}   \n",
       "preprocess_sts          {'r': 0.7133, 'pvalue': 0.0}   \n",
       "\n",
       "                                            Spearman  \n",
       "sts             {'r': 0.4871, 'pvalue': 7.2688e-130}  \n",
       "basic_sts       {'r': 0.5486, 'pvalue': 5.4266e-171}  \n",
       "preprocess_sts          {'r': 0.7064, 'pvalue': 0.0}  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_corr_results = get_pearson_spearman_results(pearsonr, b_pearson, p_pearson,\n",
    "                                               spearmanr, b_spearmanr, p_spearmanr)\n",
    "ft_corr_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d4c937cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_df.to_csv('./results/STS_results/Fasttext_model/ft_sts_results.csv', index=False)\n",
    "ft_corr_results.to_csv('./results/STS_results/Fasttext_model/ft_sts_corr_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6d774d",
   "metadata": {},
   "source": [
    "### Section 4: Contextual Representation Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9395661e",
   "metadata": {},
   "source": [
    "#### 4.1 Universal Sentence Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1b6355eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_use():\n",
    "    module_url = \"https://tfhub.dev/google/universal-sentence-encoder-large/5\" \n",
    "    use_model = hub.load(module_url)\n",
    "    print(\"module %s loaded\" % module_url)\n",
    "    return use_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "986c1e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module https://tfhub.dev/google/universal-sentence-encoder-large/5 loaded\n"
     ]
    }
   ],
   "source": [
    "use_model = get_use()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2e0a8102",
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_cossim(df, columnA, columnB, use_model):\n",
    "    \n",
    "    sts_encode1 = tf.nn.l2_normalize(use_model(tf.constant(df[columnA].tolist())), \n",
    "                                     axis=1)\n",
    "    sts_encode2 = tf.nn.l2_normalize(use_model(tf.constant(df[columnB].tolist())), \n",
    "                                     axis=1)\n",
    "    \n",
    "    cosine_similarities = tf.reduce_sum(tf.multiply(sts_encode1, sts_encode2), \n",
    "                                        axis=1)\n",
    "    return cosine_similarities\n",
    "\n",
    "def get_use_results(df, columnA, columnB, result_column):\n",
    "    \n",
    "    cos_sim = use_cossim(df, columnA, columnB, use_model)    \n",
    "    cos_sim_scores = [float(\"{:.2f}\".format(i)) for i in cos_sim.numpy().tolist()]\n",
    "    \n",
    "    df[result_column] = cos_sim_scores\n",
    "    \n",
    "    sts_scores = df['similarity_score'].tolist()\n",
    "    \n",
    "    pearson_corr = scipy.stats.pearsonr(df[result_column].tolist(), sts_scores)\n",
    "    spearmanr_corr = scipy.stats.spearmanr(df[result_column].tolist(), sts_scores)\n",
    "    \n",
    "    return pearson_corr, spearmanr_corr, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e2e0b736",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_df = sts_dev_test_updated.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c0f45916",
   "metadata": {},
   "outputs": [],
   "source": [
    "sts_pearson_corr, sts_spearmanr_corr, sts_df = get_use_results(use_df, 'sentence1', \n",
    "                                                               'sentence2', 'sts_use_score')\n",
    "\n",
    "b_pearson_corr, b_spearmanr_corr, b_sts_df = get_use_results(use_df, 'b_sentence1', \n",
    "                                                             'b_sentence2', 'b_sts_use_score')\n",
    "\n",
    "p_pearson_corr, p_spearmanr_corr, p_sts_df = get_use_results(use_df, 'p_sentence1', \n",
    "                                                             'p_sentence2', 'p_sts_use_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1799090e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pearson</th>\n",
       "      <th>Spearman</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sts</th>\n",
       "      <td>{'r': 0.8061, 'pvalue': 0.0}</td>\n",
       "      <td>{'r': 0.7954, 'pvalue': 0.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>basic_sts</th>\n",
       "      <td>{'r': 0.8013, 'pvalue': 0.0}</td>\n",
       "      <td>{'r': 0.7896, 'pvalue': 0.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preprocess_sts</th>\n",
       "      <td>{'r': 0.781, 'pvalue': 0.0}</td>\n",
       "      <td>{'r': 0.7674, 'pvalue': 0.0}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Pearson                      Spearman\n",
       "sts             {'r': 0.8061, 'pvalue': 0.0}  {'r': 0.7954, 'pvalue': 0.0}\n",
       "basic_sts       {'r': 0.8013, 'pvalue': 0.0}  {'r': 0.7896, 'pvalue': 0.0}\n",
       "preprocess_sts   {'r': 0.781, 'pvalue': 0.0}  {'r': 0.7674, 'pvalue': 0.0}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_corr_results = get_pearson_spearman_results(sts_pearson_corr, b_pearson_corr, p_pearson_corr,\n",
    "                                            sts_spearmanr_corr, b_spearmanr_corr, p_spearmanr_corr)\n",
    "use_corr_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "14aa6054",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_df.to_csv('./results/STS_results/USE_model/use_sts_results.csv', index=False)\n",
    "use_corr_results.to_csv('./results/STS_results/USE_model/use_sts_corr_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06114c55",
   "metadata": {},
   "source": [
    "#### 4.2 Sentence Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9d3891c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sent_model(model_name):\n",
    "    return SentenceTransformer(model_name)\n",
    "\n",
    "def call_sent_transformers(df, columnA, columnB, result_column, sent_model):\n",
    "    \n",
    "        ref_sent1 = df[columnA].tolist()\n",
    "        ref_sent2 = df[columnB].tolist()\n",
    "        \n",
    "        sent_embeddings1 = sent_model.encode(ref_sent1)\n",
    "        sent_embeddings2 = sent_model.encode(ref_sent2)\n",
    "        \n",
    "        cosine_scores = cosine_similarity(normalize(sent_embeddings1, axis=1), \n",
    "                                          normalize(sent_embeddings2, axis=1))\n",
    "        \n",
    "        st_scores = [float(\"{:.2f}\".format(x)) for x in list(np.diagonal(cosine_scores))]\n",
    "        df[result_column] = st_scores\n",
    "        \n",
    "        sts_scores = df['similarity_score'].tolist()\n",
    "        \n",
    "        pearson_corr = scipy.stats.pearsonr(st_scores, sts_scores)\n",
    "        spearmanr_corr = scipy.stats.spearmanr(st_scores, sts_scores)\n",
    "\n",
    "        return df, pearson_corr, spearmanr_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47f24d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sent_transformer_results(df, model_name):\n",
    "    \n",
    "    sent_model = get_sent_model(model_name)\n",
    "    \n",
    "    df, pearsonr, spearmanr = call_sent_transformers(df, 'sentence1', 'sentence2', \n",
    "                                                     'sts_st_' + model_name + '_score', sent_model)\n",
    "\n",
    "    df, b_pearsonr, b_spearmanr = call_sent_transformers(df, 'b_sentence1', 'b_sentence2', \n",
    "                                                         'b_sts_st_' + model_name + '_score', sent_model)\n",
    "\n",
    "    df, p_pearsonr, p_spearmanr = call_sent_transformers(df, 'p_sentence1', 'p_sentence2', \n",
    "                                                         'p_sts_st_' + model_name + '_score', sent_model)\n",
    "\n",
    "    corr_results = get_pearson_spearman_results(pearsonr, b_pearsonr, p_pearsonr,\n",
    "                                                 spearmanr, b_spearmanr, p_spearmanr)\n",
    "    \n",
    "    del sent_model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return corr_results, df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e2a207",
   "metadata": {},
   "source": [
    "#### 4.2.1 all-MiniLM-L6-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "84b85581",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_minilm_l6_df = sts_dev_test_updated.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "182a899b",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_res_allMiniLML6, all_minilm_l6_df = get_sent_transformer_results(all_minilm_l6_df, \n",
    "                                                                      model_name='sentence-transformers/all-MiniLM-L6-v2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9521501b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pearson</th>\n",
       "      <th>Spearman</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sts</th>\n",
       "      <td>{'r': 0.8374, 'pvalue': 0.0}</td>\n",
       "      <td>{'r': 0.8242, 'pvalue': 0.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>basic_sts</th>\n",
       "      <td>{'r': 0.8349, 'pvalue': 0.0}</td>\n",
       "      <td>{'r': 0.8202, 'pvalue': 0.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preprocess_sts</th>\n",
       "      <td>{'r': 0.8196, 'pvalue': 0.0}</td>\n",
       "      <td>{'r': 0.8041, 'pvalue': 0.0}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Pearson                      Spearman\n",
       "sts             {'r': 0.8374, 'pvalue': 0.0}  {'r': 0.8242, 'pvalue': 0.0}\n",
       "basic_sts       {'r': 0.8349, 'pvalue': 0.0}  {'r': 0.8202, 'pvalue': 0.0}\n",
       "preprocess_sts  {'r': 0.8196, 'pvalue': 0.0}  {'r': 0.8041, 'pvalue': 0.0}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_res_allMiniLML6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "55844f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_minilm_l6_df.to_csv('./results/STS_results/Sentence_transformers/all-MiniLM-L6-v2/minilm_sts_results.csv', \n",
    "                     index=False)\n",
    "\n",
    "corr_res_allMiniLML6.to_csv('./results/STS_results/Sentence_transformers/all-MiniLM-L6-v2/minilm_sts_corr_results.csv'\n",
    "                            , index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e7aebf",
   "metadata": {},
   "source": [
    "#### 4.2.2 Stsb-roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ed516c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'sentence-transformers/stsb-roberta-base-v2'\n",
    "stsb_roberta_df = sts_dev_test_updated.copy()\n",
    "\n",
    "corr_results_stsb_roberta, stsb_roberta_df = get_sent_transformer_results(stsb_roberta_df, \n",
    "                                                                          model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4fc6ecec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pearson</th>\n",
       "      <th>Spearman</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sts</th>\n",
       "      <td>{'r': 0.8766, 'pvalue': 0.0}</td>\n",
       "      <td>{'r': 0.8733, 'pvalue': 0.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>basic_sts</th>\n",
       "      <td>{'r': 0.8548, 'pvalue': 0.0}</td>\n",
       "      <td>{'r': 0.8462, 'pvalue': 0.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preprocess_sts</th>\n",
       "      <td>{'r': 0.8181, 'pvalue': 0.0}</td>\n",
       "      <td>{'r': 0.8064, 'pvalue': 0.0}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Pearson                      Spearman\n",
       "sts             {'r': 0.8766, 'pvalue': 0.0}  {'r': 0.8733, 'pvalue': 0.0}\n",
       "basic_sts       {'r': 0.8548, 'pvalue': 0.0}  {'r': 0.8462, 'pvalue': 0.0}\n",
       "preprocess_sts  {'r': 0.8181, 'pvalue': 0.0}  {'r': 0.8064, 'pvalue': 0.0}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_results_stsb_roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37a4e44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stsb_roberta_df.to_csv('./results/STS_results/Sentence_transformers/stsb-roberta-base-v2/stsb_roberta_sts_results.csv'\n",
    "                       , index=False)\n",
    "\n",
    "corr_results_stsb_roberta.to_csv('./results/STS_results/Sentence_transformers/stsb-roberta-base-v2/stsb_roberta_sts_corr_results.csv'\n",
    "                                 , index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2e1c6a",
   "metadata": {},
   "source": [
    "#### 4.3 BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a37c3725",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bert_results(df, lowercase, columnA, columnB, result_column, CLS_embedding, model, tokenizer):\n",
    "    \n",
    "        ref_sent1 = df[columnA].tolist()\n",
    "        ref_sent2 = df[columnB].tolist()\n",
    "        \n",
    "        if lowercase and result_column=='sts_st_' + model_name + '_score':\n",
    "            # special case where original sentences needs to be lower cased because the loaded \n",
    "            #uncased models are pretrained on lowercase corpus\n",
    "            \n",
    "            ref_sent1 = [preprocessor.lowercase_str(x) for x in ref_sent1]\n",
    "            ref_sent2 = [preprocessor.lowercase_str(x) for x in ref_sent2]\n",
    "        \n",
    "        encoded_input1 = tokenizer(ref_sent1, padding=True, \n",
    "                                   truncation=True, \n",
    "                                   return_tensors=\"pt\")\n",
    "        \n",
    "        encoded_input2 = tokenizer(ref_sent2, padding=True, \n",
    "                                   truncation=True, \n",
    "                                   return_tensors=\"pt\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            sent_embeddings1 = model(**encoded_input1)\n",
    "            sent_embeddings2 = model(**encoded_input2)\n",
    "            \n",
    "        if CLS_embedding:\n",
    "            embedds1 = sent_embeddings1.last_hidden_state[:, 0, :]\n",
    "            embedds2 = sent_embeddings2.last_hidden_state[:, 0, :]\n",
    "            result_column = result_column + '_CLS'\n",
    "            \n",
    "        else:\n",
    "            embedds1 = sent_embeddings1.last_hidden_state.mean(dim=1)\n",
    "            embedds2 = sent_embeddings2.last_hidden_state.mean(dim=1)\n",
    "            \n",
    "        norm_embeddings1 = torch.nn.functional.normalize(embedds1, p=2, dim=1).numpy()\n",
    "        norm_embeddings2 = torch.nn.functional.normalize(embedds2, p=2, dim=1).numpy()\n",
    "\n",
    "        cosine_scores = cosine_similarity(norm_embeddings1, norm_embeddings2)\n",
    "        bert_scores = [float(\"{:.2f}\".format(x)) for x in list(np.diagonal(cosine_scores))]\n",
    "        \n",
    "        df[result_column] = bert_scores\n",
    "        sts_scores = df['similarity_score'].tolist()\n",
    "        \n",
    "        pearson_corr = scipy.stats.pearsonr(bert_scores, sts_scores)\n",
    "        spearmanr_corr = scipy.stats.spearmanr(bert_scores, sts_scores)\n",
    "        \n",
    "        return df, pearson_corr, spearmanr_corr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f6be9157",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_bert_results(df, model_name, model, tokenizer, lowercase, CLS_embedding):\n",
    "    \n",
    "    \n",
    "    df, pearsonr, spearmanr = get_bert_results(df, lowercase, 'sentence1', 'sentence2', \n",
    "                                               'sts_st_' + model_name + '_score', CLS_embedding,\n",
    "                                               model, tokenizer)\n",
    "\n",
    "    df, b_pearsonr, b_spearmanr = get_bert_results(df, lowercase, 'b_sentence1', 'b_sentence2', \n",
    "                                                   'b_sts_' + model_name + '_score', CLS_embedding,\n",
    "                                                   model, tokenizer)\n",
    "\n",
    "    df, p_pearsonr, p_spearmanr = get_bert_results(df, lowercase, 'p_sentence1', 'p_sentence2', \n",
    "                                                   'p_sts_' + model_name + '_score', CLS_embedding,\n",
    "                                                   model, tokenizer)\n",
    "\n",
    "    corr_results = get_pearson_spearman_results(pearsonr, b_pearsonr, p_pearsonr,\n",
    "                                                 spearmanr, b_spearmanr, p_spearmanr)\n",
    "    \n",
    "    return corr_results, df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c70e2768",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"bert-base-uncased\"\n",
    "\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "bert_model = BertModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511f7b4c",
   "metadata": {},
   "source": [
    "#### 4.3.1 bert avg. embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f5d10395",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_avg_df = sts_dev_test_updated.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3930a61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_res_avg, bert_avg_df = call_bert_results(bert_avg_df, model_name, bert_model, \n",
    "                                              bert_tokenizer,\n",
    "                                              lowercase=True, CLS_embedding=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "41eb74f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pearson</th>\n",
       "      <th>Spearman</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sts</th>\n",
       "      <td>{'r': 0.5921, 'pvalue': 9.4414e-206}</td>\n",
       "      <td>{'r': 0.5924, 'pvalue': 5.4604e-206}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>basic_sts</th>\n",
       "      <td>{'r': 0.5866, 'pvalue': 4.152e-201}</td>\n",
       "      <td>{'r': 0.5855, 'pvalue': 3.7507e-200}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preprocess_sts</th>\n",
       "      <td>{'r': 0.6141, 'pvalue': 2.0284e-225}</td>\n",
       "      <td>{'r': 0.6029, 'pvalue': 3.2489e-215}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Pearson  \\\n",
       "sts             {'r': 0.5921, 'pvalue': 9.4414e-206}   \n",
       "basic_sts        {'r': 0.5866, 'pvalue': 4.152e-201}   \n",
       "preprocess_sts  {'r': 0.6141, 'pvalue': 2.0284e-225}   \n",
       "\n",
       "                                            Spearman  \n",
       "sts             {'r': 0.5924, 'pvalue': 5.4604e-206}  \n",
       "basic_sts       {'r': 0.5855, 'pvalue': 3.7507e-200}  \n",
       "preprocess_sts  {'r': 0.6029, 'pvalue': 3.2489e-215}  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_res_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5cc18ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_avg_df.to_csv('./results/STS_results/BERT_models/BERT_Avg_Embeddings/bert_avg_sts_results.csv', \n",
    "                     index=False)\n",
    "bert_res_avg.to_csv('./results/STS_results/BERT_models/BERT_Avg_Embeddings/bert_avg_sts_corr_results.csv', \n",
    "                    index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91db5aac",
   "metadata": {},
   "source": [
    "#### 4.3.2 bert CLS embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7e5c74fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_cls_df = sts_dev_test_updated.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2af37821",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_corr_res_cls, bert_cls_df = call_bert_results(bert_cls_df, model_name, bert_model, \n",
    "                                              bert_tokenizer,\n",
    "                                              lowercase=True, CLS_embedding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2a060b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pearson</th>\n",
       "      <th>Spearman</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sts</th>\n",
       "      <td>{'r': 0.313, 'pvalue': 1.3621e-50}</td>\n",
       "      <td>{'r': 0.3445, 'pvalue': 1.3898e-61}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>basic_sts</th>\n",
       "      <td>{'r': 0.3414, 'pvalue': 1.8817e-60}</td>\n",
       "      <td>{'r': 0.3723, 'pvalue': 2.0093e-72}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preprocess_sts</th>\n",
       "      <td>{'r': 0.4081, 'pvalue': 5.3893e-88}</td>\n",
       "      <td>{'r': 0.437, 'pvalue': 4.9384e-102}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Pearson  \\\n",
       "sts              {'r': 0.313, 'pvalue': 1.3621e-50}   \n",
       "basic_sts       {'r': 0.3414, 'pvalue': 1.8817e-60}   \n",
       "preprocess_sts  {'r': 0.4081, 'pvalue': 5.3893e-88}   \n",
       "\n",
       "                                           Spearman  \n",
       "sts             {'r': 0.3445, 'pvalue': 1.3898e-61}  \n",
       "basic_sts       {'r': 0.3723, 'pvalue': 2.0093e-72}  \n",
       "preprocess_sts  {'r': 0.437, 'pvalue': 4.9384e-102}  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_corr_res_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b75f7200",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_cls_df.to_csv('./results/STS_results/BERT_models/BERT_CLS_Embeddings/bert_cls_sts_results.csv', \n",
    "                     index=False)\n",
    "bert_corr_res_cls.to_csv('./results/STS_results/BERT_models/BERT_CLS_Embeddings/bert_cls_sts_corr_results.csv', \n",
    "                    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d0b931be",
   "metadata": {},
   "outputs": [],
   "source": [
    "del bert_model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
