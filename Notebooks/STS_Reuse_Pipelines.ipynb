{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc486195",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/sarba/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/sarba/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "import torch\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "\n",
    "import math\n",
    "import scipy\n",
    "\n",
    "import requests\n",
    "import zipfile\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import gc\n",
    "from transformers import BertTokenizer, BertModel, RobertaTokenizer, RobertaModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "818fc87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install datasets==2.16.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67f924f",
   "metadata": {},
   "source": [
    "### Section 0: Load & Preprocess STS Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ac5e541",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"stsb_multi_mt\", name=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bc5c41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sts_train = dataset['train'].to_pandas()\n",
    "sts_test = dataset['test'].to_pandas()\n",
    "sts_dev = dataset['dev'].to_pandas()\n",
    "\n",
    "sts_dev_test = pd.concat([sts_dev, sts_test], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b4ec9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_updated_df(df):\n",
    "    \n",
    "    char_count_columns = df[['sentence1', 'sentence2']].astype(str).applymap(len)\n",
    "    df = df[char_count_columns.gt(30).all(axis=1)]\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def format_float(x):\n",
    "    if isinstance(x, float):\n",
    "        if x.is_integer():\n",
    "            return x\n",
    "        else:\n",
    "            return float(\"{:.3f}\".format(x))\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "def sim_score_conversion(df):\n",
    "\n",
    "    # scale the human-rated values between 0 and 1\n",
    "\n",
    "    hr_value_scaling = sklearn.preprocessing.minmax_scale(df['similarity_score'].tolist(), \n",
    "                                                          feature_range=(0, 1), \n",
    "                                                          axis=0, copy=True).tolist()\n",
    "\n",
    "    # set a threshold to convert the scaled values into boolean labels\n",
    "    similarity_threshold = 0.60\n",
    "    ground_truth_labels = [True if score >= similarity_threshold else False \n",
    "                           for score in hr_value_scaling]\n",
    "\n",
    "    df['gt_similar'] = ground_truth_labels\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6c940b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sts_dev_test_updated = get_updated_df(sts_dev_test)\n",
    "sts_dev_test_updated = sim_score_conversion(sts_dev_test_updated)\n",
    "\n",
    "sts_train_updated = get_updated_df(sts_train)\n",
    "sts_train_updated = sim_score_conversion(sts_train_updated)\n",
    "\n",
    "\n",
    "sts_dev_test_updated['similarity_score'] = sts_dev_test_updated['similarity_score'].apply(format_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7ab0832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gt_similar\n",
       "False    1139\n",
       "True     1034\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sts_dev_test_updated.gt_similar.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8362e51",
   "metadata": {},
   "source": [
    "#### 0.1 Preprocess STS dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e84decfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessing:\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    def rm_specialchars(self, text):\n",
    "\n",
    "        line = re.sub(r\"http\\S+\", \"\", text)\n",
    "        line = re.sub(\"[^A-Za-z]+\", \" \", line)\n",
    "        line = re.sub('\\s+', ' ', line)\n",
    "        line = line.replace('\\t',' ')\n",
    "        line = line.replace('\\n',' ')\n",
    "        line = line.replace('\\r',' ')\n",
    "        line = line.replace(',',' ')\n",
    "        line = line.replace('-',' ')\n",
    "        return line.strip()\n",
    "\n",
    "\n",
    "    def rm_stopwords(self, text):\n",
    "\n",
    "        word_tokens = word_tokenize(text)\n",
    "        filtered_text = [word for word in word_tokens if word not in self.stop_words]\n",
    "        return ' '.join(filtered_text)\n",
    "\n",
    "\n",
    "    def lemmatize_str(self, text):\n",
    "        \n",
    "        lemma_text = [self.lemmatizer.lemmatize(word) for word in text]\n",
    "        return (''.join(lemma_text)).strip()\n",
    "    \n",
    "\n",
    "    def lowercase_str(self, text):\n",
    "        \n",
    "        return text.lower()\n",
    "\n",
    "\n",
    "    def basic_preprocess(self, text):\n",
    "        \"\"\"\n",
    "        In basic preprocess: lowercase the string, remove special characters and lemmatize.\n",
    "        \"\"\"\n",
    "        \n",
    "        l_str = self.lowercase_str(text)\n",
    "        sc_str = self.rm_specialchars(l_str)\n",
    "        updated_text = self.lemmatize_str(sc_str)\n",
    "        \n",
    "        return updated_text\n",
    "    \n",
    "    def preprocess(self, text):\n",
    "        \"\"\"\n",
    "        In preprocess:  lowercase the string, remove special characters and stop words.\n",
    "        Finally, lemmatize the string.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        l_str = self.lowercase_str(text)\n",
    "        sc_str = self.rm_specialchars(l_str)\n",
    "        sw_str = self.rm_stopwords(sc_str)\n",
    "        updated_text = self.lemmatize_str(sw_str)\n",
    "        \n",
    "        return updated_text\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5adadbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = Preprocessing()\n",
    "\n",
    "def apply_preprocessing(preprocessor, df):\n",
    "    \n",
    "    df['b_sentence1'] = df['sentence1'].apply(lambda x: preprocessor.basic_preprocess(x))\n",
    "    df['b_sentence2'] = df['sentence2'].apply(lambda x: preprocessor.basic_preprocess(x))\n",
    "    \n",
    "    df['p_sentence1'] = df['sentence1'].apply(lambda x: preprocessor.preprocess(x))\n",
    "    df['p_sentence2'] = df['sentence2'].apply(lambda x: preprocessor.preprocess(x))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11a57098",
   "metadata": {},
   "outputs": [],
   "source": [
    "sts_train_updated = apply_preprocessing(preprocessor, sts_train_updated)\n",
    "sts_dev_test_updated = apply_preprocessing(preprocessor, sts_dev_test_updated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d077271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>similarity_score</th>\n",
       "      <th>gt_similar</th>\n",
       "      <th>b_sentence1</th>\n",
       "      <th>b_sentence2</th>\n",
       "      <th>p_sentence1</th>\n",
       "      <th>p_sentence2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A man with a hard hat is dancing.</td>\n",
       "      <td>A man wearing a hard hat is dancing.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>a man with a hard hat is dancing</td>\n",
       "      <td>a man wearing a hard hat is dancing</td>\n",
       "      <td>man hard hat dancing</td>\n",
       "      <td>man wearing hard hat dancing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A man is feeding a mouse to a snake.</td>\n",
       "      <td>The man is feeding a mouse to the snake.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>a man is feeding a mouse to a snake</td>\n",
       "      <td>the man is feeding a mouse to the snake</td>\n",
       "      <td>man feeding mouse snake</td>\n",
       "      <td>man feeding mouse snake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A man is erasing a chalk board.</td>\n",
       "      <td>The man is erasing the chalk board.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>a man is erasing a chalk board</td>\n",
       "      <td>the man is erasing the chalk board</td>\n",
       "      <td>man erasing chalk board</td>\n",
       "      <td>man erasing chalk board</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>The man cut down a tree with an axe.</td>\n",
       "      <td>A man chops down a tree with an axe.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>the man cut down a tree with an axe</td>\n",
       "      <td>a man chops down a tree with an axe</td>\n",
       "      <td>man cut tree axe</td>\n",
       "      <td>man chops tree axe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>The girl sang into a microphone.</td>\n",
       "      <td>The lady sang into the microphone.</td>\n",
       "      <td>2.4</td>\n",
       "      <td>False</td>\n",
       "      <td>the girl sang into a microphone</td>\n",
       "      <td>the lady sang into the microphone</td>\n",
       "      <td>girl sang microphone</td>\n",
       "      <td>lady sang microphone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               sentence1  \\\n",
       "0      A man with a hard hat is dancing.   \n",
       "2   A man is feeding a mouse to a snake.   \n",
       "6        A man is erasing a chalk board.   \n",
       "13  The man cut down a tree with an axe.   \n",
       "16      The girl sang into a microphone.   \n",
       "\n",
       "                                   sentence2  similarity_score  gt_similar  \\\n",
       "0       A man wearing a hard hat is dancing.               5.0        True   \n",
       "2   The man is feeding a mouse to the snake.               5.0        True   \n",
       "6        The man is erasing the chalk board.               5.0        True   \n",
       "13      A man chops down a tree with an axe.               5.0        True   \n",
       "16        The lady sang into the microphone.               2.4       False   \n",
       "\n",
       "                            b_sentence1  \\\n",
       "0      a man with a hard hat is dancing   \n",
       "2   a man is feeding a mouse to a snake   \n",
       "6        a man is erasing a chalk board   \n",
       "13  the man cut down a tree with an axe   \n",
       "16      the girl sang into a microphone   \n",
       "\n",
       "                                b_sentence2              p_sentence1  \\\n",
       "0       a man wearing a hard hat is dancing     man hard hat dancing   \n",
       "2   the man is feeding a mouse to the snake  man feeding mouse snake   \n",
       "6        the man is erasing the chalk board  man erasing chalk board   \n",
       "13      a man chops down a tree with an axe         man cut tree axe   \n",
       "16        the lady sang into the microphone     girl sang microphone   \n",
       "\n",
       "                     p_sentence2  \n",
       "0   man wearing hard hat dancing  \n",
       "2        man feeding mouse snake  \n",
       "6        man erasing chalk board  \n",
       "13            man chops tree axe  \n",
       "16          lady sang microphone  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sts_dev_test_updated.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842e43ca",
   "metadata": {},
   "source": [
    "#### 0.2 Util Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "933d69ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction_values(similarities, df, preprocess_type):\n",
    "    \n",
    "    # get the highest similar index in each item\n",
    "    highest_similarity_indices = np.argmax(similarities, axis=1).tolist()\n",
    "    \n",
    "    # get the top cosine similarity of sentence2 based on index value\n",
    "    df['top_similar_sentence2_score'] = [similarities[i, index] for i, index \n",
    "                                         in enumerate(highest_similarity_indices)]\n",
    "    \n",
    "    if preprocess_type == 'basic':\n",
    "        \n",
    "        # get the top similar sentence2 based on index value\n",
    "        df['top_similar_sentence2'] = [df['b_sentence2'].tolist()[index] for index \n",
    "                                       in highest_similarity_indices]\n",
    "    \n",
    "    elif preprocess_type == 'preprocess':\n",
    "        \n",
    "        # get the top similar sentence2 based on index value\n",
    "        df['top_similar_sentence2'] = [df['p_sentence2'].tolist()[index] for index \n",
    "                                       in highest_similarity_indices]\n",
    "    \n",
    "    else:\n",
    "        df['top_similar_sentence2'] = [df['sentence2'].tolist()[index] for index \n",
    "                                       in highest_similarity_indices]\n",
    "        \n",
    "    \n",
    "    # add a column related to top similar sentence indicies\n",
    "    df['top_similar_sentence2_index'] = highest_similarity_indices\n",
    "    \n",
    "    # check if index of row matches with the index of highest similar sentence index\n",
    "    df['is_index_match'] = [i == index for i, index in enumerate(highest_similarity_indices)]\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e4b288d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_predictions(df):\n",
    "    \n",
    "    \"\"\"\n",
    "    True Positives (TP): Cases where is_index_match is True.\n",
    "\n",
    "    False Negatives (FN): Cases where gt_similar is True (indicating the sentences are similar) \n",
    "    but is_index_match is False (the model did not identify them as the top match).\n",
    "\n",
    "    False Positives (FP): Cases where the model identified them as a match (i.e., is_index_match is True), \n",
    "    but they are not actually matches according to gt_similar.\n",
    "\n",
    "    \"\"\"\n",
    "    TP = df['is_index_match'].sum()\n",
    "\n",
    "    FN = df[(df['gt_similar'] == True) & (df['is_index_match'] == False)].shape[0]\n",
    "\n",
    "    FP = df[(df['gt_similar'] == False) & (df['is_index_match'] == True)].shape[0]\n",
    "\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    f1_score = 2 * precision * recall / (precision + recall) if precision + recall > 0 else 0\n",
    "\n",
    "    return format_float(precision), format_float(recall), format_float(f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075b572f",
   "metadata": {},
   "source": [
    "### Section 1: Weighted Representation Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7cca16",
   "metadata": {},
   "source": [
    "#### 1.1 tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81434f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectorizer(text_preprocessed):\n",
    "    \n",
    "    if text_preprocessed:\n",
    "        vectorizer = TfidfVectorizer(min_df=3, max_df=0.5, \n",
    "                                     ngram_range=(1,3), \n",
    "                                     stop_words=None)\n",
    "\n",
    "        \n",
    "    else:\n",
    "        vectorizer = TfidfVectorizer(min_df=3, max_df=0.5, \n",
    "                                     ngram_range=(1,3), \n",
    "                                     lowercase=False,\n",
    "                                     stop_words=None) \n",
    " \n",
    "    return vectorizer\n",
    "\n",
    "\n",
    "def get_train_vecs(df_train, columnA, columnB):\n",
    "        \n",
    "    train_sents = df_train[[columnA, columnB]].values.tolist()\n",
    "    train_sents = [item for sublist in train_sents for item in sublist]\n",
    "\n",
    "    return train_sents\n",
    "\n",
    "\n",
    "def get_tfidf_results(df_train, df_test, columnA, columnB,\n",
    "                      text_preprocessed, preprocess_type):\n",
    "    \n",
    "    train_sents = get_train_vecs(df_train, columnA, columnB)\n",
    "    vectorizer = get_vectorizer(text_preprocessed)\n",
    "    vectorizer.fit_transform(train_sents)\n",
    "    \n",
    "    list1 = vectorizer.transform(df_test[columnA].tolist())\n",
    "    list2 = normalize(list1.toarray())\n",
    "    \n",
    "    list2 = vectorizer.transform(df_test[columnB].tolist())\n",
    "    list2 = normalize(list2.toarray())\n",
    "    \n",
    "    sims_scores = cosine_similarity(list1, list2)\n",
    "    \n",
    "    updated_df = get_prediction_values(sims_scores, df_test, preprocess_type)\n",
    "    \n",
    "    precision, recall, f1_score = evaluate_predictions(updated_df)\n",
    "    \n",
    "    return precision, recall, f1_score, updated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0b9bd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_train_df = sts_train_updated.copy()\n",
    "tfidf_test_df = sts_dev_test_updated.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f034c4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, f1_score, tfidf_df = get_tfidf_results(tfidf_train_df, tfidf_test_df,\n",
    "                                                          'sentence1', 'sentence2', \n",
    "                                                          text_preprocessed=False, \n",
    "                                                          preprocess_type=None)\n",
    "\n",
    "\n",
    "bprecision, brecall, bf1_score, btfidf_df = get_tfidf_results(tfidf_train_df, tfidf_test_df,\n",
    "                                                              'b_sentence1', 'b_sentence2', \n",
    "                                                              text_preprocessed=True, \n",
    "                                                              preprocess_type='basic')\n",
    "\n",
    "pprecision, precall, pf1_score, ptfidf_df = get_tfidf_results(tfidf_train_df, tfidf_test_df,\n",
    "                                                              'p_sentence1', 'p_sentence2', \n",
    "                                                              text_preprocessed=True, \n",
    "                                                              preprocess_type='preprocess')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b1eb3b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>similarity_score</th>\n",
       "      <th>gt_similar</th>\n",
       "      <th>b_sentence1</th>\n",
       "      <th>b_sentence2</th>\n",
       "      <th>p_sentence1</th>\n",
       "      <th>p_sentence2</th>\n",
       "      <th>top_similar_sentence2_score</th>\n",
       "      <th>top_similar_sentence2</th>\n",
       "      <th>top_similar_sentence2_index</th>\n",
       "      <th>is_index_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A man with a hard hat is dancing.</td>\n",
       "      <td>A man wearing a hard hat is dancing.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>a man with a hard hat is dancing</td>\n",
       "      <td>a man wearing a hard hat is dancing</td>\n",
       "      <td>man hard hat dancing</td>\n",
       "      <td>man wearing hard hat dancing</td>\n",
       "      <td>0.819109</td>\n",
       "      <td>man wearing hard hat dancing</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A man is feeding a mouse to a snake.</td>\n",
       "      <td>The man is feeding a mouse to the snake.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>a man is feeding a mouse to a snake</td>\n",
       "      <td>the man is feeding a mouse to the snake</td>\n",
       "      <td>man feeding mouse snake</td>\n",
       "      <td>man feeding mouse snake</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>man feeding mouse snake</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A man is erasing a chalk board.</td>\n",
       "      <td>The man is erasing the chalk board.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>a man is erasing a chalk board</td>\n",
       "      <td>the man is erasing the chalk board</td>\n",
       "      <td>man erasing chalk board</td>\n",
       "      <td>man erasing chalk board</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>man erasing chalk board</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>The man cut down a tree with an axe.</td>\n",
       "      <td>A man chops down a tree with an axe.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>the man cut down a tree with an axe</td>\n",
       "      <td>a man chops down a tree with an axe</td>\n",
       "      <td>man cut tree axe</td>\n",
       "      <td>man chops tree axe</td>\n",
       "      <td>0.866955</td>\n",
       "      <td>man chops tree axe</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>The girl sang into a microphone.</td>\n",
       "      <td>The lady sang into the microphone.</td>\n",
       "      <td>2.4</td>\n",
       "      <td>False</td>\n",
       "      <td>the girl sang into a microphone</td>\n",
       "      <td>the lady sang into the microphone</td>\n",
       "      <td>girl sang microphone</td>\n",
       "      <td>lady sang microphone</td>\n",
       "      <td>0.592113</td>\n",
       "      <td>lady sang microphone</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               sentence1  \\\n",
       "0      A man with a hard hat is dancing.   \n",
       "2   A man is feeding a mouse to a snake.   \n",
       "6        A man is erasing a chalk board.   \n",
       "13  The man cut down a tree with an axe.   \n",
       "16      The girl sang into a microphone.   \n",
       "\n",
       "                                   sentence2  similarity_score  gt_similar  \\\n",
       "0       A man wearing a hard hat is dancing.               5.0        True   \n",
       "2   The man is feeding a mouse to the snake.               5.0        True   \n",
       "6        The man is erasing the chalk board.               5.0        True   \n",
       "13      A man chops down a tree with an axe.               5.0        True   \n",
       "16        The lady sang into the microphone.               2.4       False   \n",
       "\n",
       "                            b_sentence1  \\\n",
       "0      a man with a hard hat is dancing   \n",
       "2   a man is feeding a mouse to a snake   \n",
       "6        a man is erasing a chalk board   \n",
       "13  the man cut down a tree with an axe   \n",
       "16      the girl sang into a microphone   \n",
       "\n",
       "                                b_sentence2              p_sentence1  \\\n",
       "0       a man wearing a hard hat is dancing     man hard hat dancing   \n",
       "2   the man is feeding a mouse to the snake  man feeding mouse snake   \n",
       "6        the man is erasing the chalk board  man erasing chalk board   \n",
       "13      a man chops down a tree with an axe         man cut tree axe   \n",
       "16        the lady sang into the microphone     girl sang microphone   \n",
       "\n",
       "                     p_sentence2  top_similar_sentence2_score  \\\n",
       "0   man wearing hard hat dancing                     0.819109   \n",
       "2        man feeding mouse snake                     1.000000   \n",
       "6        man erasing chalk board                     1.000000   \n",
       "13            man chops tree axe                     0.866955   \n",
       "16          lady sang microphone                     0.592113   \n",
       "\n",
       "           top_similar_sentence2  top_similar_sentence2_index  is_index_match  \n",
       "0   man wearing hard hat dancing                            0            True  \n",
       "2        man feeding mouse snake                            1            True  \n",
       "6        man erasing chalk board                            2            True  \n",
       "13            man chops tree axe                            3            True  \n",
       "16          lady sang microphone                            4            True  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptfidf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "524a08ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.773 0.761 0.767\n",
      "0.775 0.783 0.779\n",
      "0.786 0.777 0.782\n"
     ]
    }
   ],
   "source": [
    "print(precision, recall, f1_score)\n",
    "print(bprecision, brecall, bf1_score)\n",
    "print(pprecision, precall, pf1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fad69b0",
   "metadata": {},
   "source": [
    "### Section 2: String-level "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71d4177",
   "metadata": {},
   "source": [
    "#### 2.1 JSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9f605546",
   "metadata": {},
   "outputs": [],
   "source": [
    "jsi_df = sts_dev_test_updated.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "93e87762",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(sentence1, sentence2):\n",
    "    \n",
    "    tokens1 = set(sentence1.split())\n",
    "    tokens2 = set(sentence2.split())\n",
    "    intersection = len(tokens1.intersection(tokens2))    \n",
    "    return float(intersection) / (len(tokens1) + len(tokens2) - intersection)\n",
    "\n",
    "def find_highest_jsi(df, columnA, columnB, preprocess_type):\n",
    "\n",
    "    jsi_results = []\n",
    "    ref_sent1 = df[columnA].tolist()\n",
    "    ref_sent2 = df[columnB].tolist()\n",
    "    \n",
    "    similarity_matrix = np.zeros((len(ref_sent1), len(ref_sent2)))\n",
    "    \n",
    "    for i, sentence1 in enumerate(ref_sent1):\n",
    "        for j, sentence2 in enumerate(ref_sent2):\n",
    "            similarity_matrix[i, j] = jaccard_similarity(sentence1, sentence2)\n",
    "            \n",
    "    updated_df = get_prediction_values(similarity_matrix, df, preprocess_type)\n",
    "    precision, recall, f1_score = evaluate_predictions(updated_df)\n",
    "\n",
    "    return precision, recall, f1_score, updated_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "30c938cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, f1_score, updated_df = find_highest_jsi(jsi_df, 'sentence1', 'sentence2', \n",
    "                                                           preprocess_type=None)\n",
    "\n",
    "bprecision, brecall, bf1_score, bupdated_df = find_highest_jsi(jsi_df, 'b_sentence1', 'b_sentence2',\n",
    "                                                              preprocess_type='basic')\n",
    "\n",
    "pprecision, precall, pf1_score, pupdated_df = find_highest_jsi(jsi_df, 'p_sentence1', 'p_sentence2', \n",
    "                                                               preprocess_type='preprocess')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2b6b7ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.772 0.795 0.783\n",
      "0.772 0.84 0.805\n",
      "0.769 0.853 0.809\n"
     ]
    }
   ],
   "source": [
    "print(precision, recall, f1_score)\n",
    "print(bprecision, brecall, bf1_score)\n",
    "print(pprecision, precall, pf1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59af3422",
   "metadata": {},
   "source": [
    "### Section 3: Distributed Representation Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7817b26a",
   "metadata": {},
   "source": [
    "#### 3.1 Glove word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "be873db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_model_url = 'https://nlp.stanford.edu/data/glove.6B.zip'\n",
    "save_dir = './models/glove_model'\n",
    "\n",
    "response = requests.get(glove_model_url)\n",
    "\n",
    "zip_file_path = os.path.join(save_dir, 'glove.6B.zip')\n",
    "\n",
    "with open(zip_file_path, 'wb') as f:\n",
    "    f.write(response.content)\n",
    "\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall('./models/glove_model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e358e483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000 words loaded!\n"
     ]
    }
   ],
   "source": [
    "def load_glove_model(File):\n",
    "    \n",
    "    glove_model = {}\n",
    "    \n",
    "    with open(File,'r') as f:\n",
    "        for line in f:\n",
    "            split_line = line.split()\n",
    "            word = split_line[0]\n",
    "            embedding = np.array(split_line[1:], dtype=np.float64)\n",
    "            glove_model[word] = embedding\n",
    "    \n",
    "    print(f\"{len(glove_model)} words loaded!\")\n",
    "    return glove_model\n",
    "\n",
    "glove_model = load_glove_model('./models/glove_model/glove.6B.300d.txt')\n",
    "glove_vocab = list(glove_model.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "11f1bd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2vec_similarity(df, columnA, columnB, \n",
    "                        glove_model, glove_vocab, preprocessor, preprocess_type):\n",
    "    \n",
    "    ref_sent1 = df[columnA].tolist()\n",
    "    ref_sent2 = df[columnB].tolist()\n",
    "\n",
    "    ref_sent1 = [preprocessor.lowercase_str(x) for x in ref_sent1]\n",
    "    ref_sent2 = [preprocessor.lowercase_str(x) for x in ref_sent2]\n",
    "\n",
    "    glove_embeds1 = [[glove_model[word] for word in sentence.split() if word in glove_vocab] \n",
    "                     for sentence in ref_sent1]\n",
    "    \n",
    "    glove_embeds2 = [[glove_model[word] for word in sentence.split() if word in glove_vocab] \n",
    "                     for sentence in ref_sent2]\n",
    "\n",
    "    sent_vec1 = [np.mean(normalize(wordvec, axis=1), axis=0) for wordvec in glove_embeds1]\n",
    "    sent_vec2 = [np.mean(normalize(wordvec, axis=1), axis=0) for wordvec in glove_embeds2]\n",
    "    \n",
    "    sims_scores = cosine_similarity(sent_vec1, sent_vec2)\n",
    "    updated_df = get_prediction_values(sims_scores, df, preprocess_type)\n",
    "    \n",
    "    precision, recall, f1_score = evaluate_predictions(updated_df)\n",
    "    \n",
    "    return precision, recall, f1_score, updated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "18cb87a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_glove_df = sts_dev_test_updated.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6bcefacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, f1_score, word2vec_glove_df_updated = word2vec_similarity(word2vec_glove_df,\n",
    "                                                                             'sentence1', 'sentence2',  \n",
    "                                                                             glove_model, glove_vocab, \n",
    "                                                                             preprocessor, \n",
    "                                                                             preprocess_type= None)\n",
    "\n",
    "bprecision, brecall, bf1_score, bword2vec_glove_df_updated = word2vec_similarity(word2vec_glove_df,\n",
    "                                                                                 'b_sentence1', 'b_sentence2',  \n",
    "                                                                                 glove_model, glove_vocab, \n",
    "                                                                                 preprocessor, \n",
    "                                                                                 preprocess_type = 'basic')\n",
    "\n",
    "pprecision, precall, pf1_score, pword2vec_glove_df_updated = word2vec_similarity(word2vec_glove_df,\n",
    "                                                                                 'p_sentence1', 'p_sentence2',  \n",
    "                                                                                 glove_model, glove_vocab, \n",
    "                                                                                 preprocessor,\n",
    "                                                                                 preprocess_type='preprocess')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "081a2386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.774 0.76 0.767\n",
      "0.766 0.81 0.787\n",
      "0.775 0.851 0.812\n"
     ]
    }
   ],
   "source": [
    "print(precision, recall, f1_score)\n",
    "print(bprecision, brecall, bf1_score)\n",
    "print(pprecision, precall, pf1_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5c9a9d",
   "metadata": {},
   "source": [
    "#### 3.2 FastText Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "686dcf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "\n",
    "#  download ft model\n",
    "#import fasttext.util\n",
    "#fasttext.util.download_model('en', if_exists='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7fe27f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "ft = fasttext.load_model('./models/cc.en.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d085cd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fasttext_similarity(df, columnA, columnB, ft, preprocess_type):\n",
    "    \n",
    "    ref_sent1 = df[columnA].tolist()\n",
    "    ref_sent2 = df[columnB].tolist()\n",
    "\n",
    "    ft_embeds1 = [ft.get_sentence_vector(sent) for sent in ref_sent1]    \n",
    "    ft_embeds2 = [ft.get_sentence_vector(sent) for sent in ref_sent2]\n",
    "    \n",
    "    sims_scores = cosine_similarity(ft_embeds1, ft_embeds2)\n",
    "    updated_df = get_prediction_values(sims_scores, df, preprocess_type)\n",
    "    \n",
    "    precision, recall, f1_score = evaluate_predictions(updated_df)\n",
    "    \n",
    "    return precision, recall, f1_score, updated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "40cd3c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_df = sts_dev_test_updated.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6c37f463",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, f1_score, ft_df_updated = fasttext_similarity(ft_df,\n",
    "                                                                 'sentence1', 'sentence2',  \n",
    "                                                                 ft, preprocess_type= None)\n",
    "\n",
    "bprecision, brecall, bf1_score, bft_df_updated = fasttext_similarity(ft_df,\n",
    "                                                                     'b_sentence1', 'b_sentence2',  \n",
    "                                                                     ft, preprocess_type= 'basic')\n",
    "\n",
    "pprecision, precall, pf1_score, pft_df_updated = fasttext_similarity(ft_df,\n",
    "                                                                     'p_sentence1', 'p_sentence2',  \n",
    "                                                                     ft, preprocess_type= 'preprocess')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cb6cbc1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.776 0.796 0.786\n",
      "0.774 0.819 0.796\n",
      "0.772 0.867 0.817\n"
     ]
    }
   ],
   "source": [
    "print(precision, recall, f1_score)\n",
    "print(bprecision, brecall, bf1_score)\n",
    "print(pprecision, precall, pf1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284c6fb7",
   "metadata": {},
   "source": [
    "### Section 4: Contextual Representation Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02060a70",
   "metadata": {},
   "source": [
    "#### 4.1 Universal Sentence Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "44751f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module https://tfhub.dev/google/universal-sentence-encoder-large/5 loaded\n"
     ]
    }
   ],
   "source": [
    "def get_use():\n",
    "    module_url = \"https://tfhub.dev/google/universal-sentence-encoder-large/5\" \n",
    "    use_model = hub.load(module_url)\n",
    "    print(\"module %s loaded\" % module_url)\n",
    "    return use_model\n",
    "\n",
    "use_model = get_use()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "10b50c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_cossim(df, columnA, columnB, use_model):\n",
    "    \n",
    "\n",
    "    sts_encode1 = tf.nn.l2_normalize(use_model(tf.constant(df[columnA].tolist())), \n",
    "                                     axis=1)\n",
    "    sts_encode2 = tf.nn.l2_normalize(use_model(tf.constant(df[columnB].tolist())), \n",
    "                                     axis=1)\n",
    "    \n",
    "    cosine_similarities = cosine_similarity(sts_encode1, sts_encode2)\n",
    "\n",
    "    return cosine_similarities\n",
    "\n",
    "def get_use_results(df, columnA, columnB, preprocess_type):\n",
    "    \n",
    "    similarities = use_cossim(df, columnA, columnB, use_model)\n",
    "\n",
    "    updated_df = get_prediction_values(similarities, df, preprocess_type)\n",
    "    \n",
    "    precision, recall, f1_score = evaluate_predictions(updated_df)\n",
    "    \n",
    "    return precision, recall, f1_score, updated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9e79f8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_df = sts_dev_test_updated.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e81e68a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_precision, use_recall, use_f1_score, use_sts_df = get_use_results(use_df, 'sentence1', \n",
    "                                                                      'sentence2', preprocess_type=None)\n",
    "\n",
    "buse_precision, buse_recall, buse_f1_score, buse_sts_df = get_use_results(use_df, 'b_sentence1', \n",
    "                                                                          'b_sentence2', preprocess_type='basic')\n",
    "\n",
    "puse_precision, puse_recall, puse_f1_score, puse_sts_df = get_use_results(use_df, 'p_sentence1', \n",
    "                                                                          'p_sentence2',\n",
    "                                                                          preprocess_type='preprocess')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "18256615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.755 0.903 0.822\n",
      "0.757 0.902 0.823\n",
      "0.761 0.897 0.824\n"
     ]
    }
   ],
   "source": [
    "print(use_precision, use_recall, use_f1_score)\n",
    "print(buse_precision, buse_recall, buse_f1_score)\n",
    "print(puse_precision, puse_recall, puse_f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3c7d28",
   "metadata": {},
   "source": [
    "#### 4.2 Sentence Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9d3891c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sent_model(model_name):\n",
    "    return SentenceTransformer(model_name)\n",
    "\n",
    "def call_sent_transformers(df, columnA, columnB, sent_model, preprocess_type):\n",
    "    \n",
    "        ref_sent1 = df[columnA].tolist()\n",
    "        ref_sent2 = df[columnB].tolist()\n",
    "        \n",
    "        sent_embeddings1 = sent_model.encode(ref_sent1)\n",
    "        sent_embeddings2 = sent_model.encode(ref_sent2)\n",
    "        \n",
    "        cosine_scores = cosine_similarity(normalize(sent_embeddings1, axis=1), \n",
    "                                          normalize(sent_embeddings2, axis=1))\n",
    "        \n",
    "        updated_df = get_prediction_values(cosine_scores, df, preprocess_type)\n",
    "\n",
    "        precision, recall, f1_score = evaluate_predictions(updated_df)\n",
    "\n",
    "        return precision, recall, f1_score, updated_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed71e588",
   "metadata": {},
   "source": [
    "#### 4.2.1 all-MiniLM-L6-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "84b85581",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_minilm_l6_df = sts_dev_test_updated.copy()\n",
    "\n",
    "sent_model = get_sent_model('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "abe3c186",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "precision, recall, f1_score, updated_df = call_sent_transformers(all_minilm_l6_df, 'sentence1', \n",
    "                                                                 'sentence2', \n",
    "                                                                 sent_model, \n",
    "                                                                 preprocess_type=None)\n",
    "\n",
    "b_precision, b_recall, b_f1_score, b_updated_df = call_sent_transformers(all_minilm_l6_df, 'b_sentence1', \n",
    "                                                                         'b_sentence2', \n",
    "                                                                         sent_model, \n",
    "                                                                         preprocess_type='basic')\n",
    "\n",
    "p_precision, p_recall, p_f1_score, p_updated_df = call_sent_transformers(all_minilm_l6_df, 'p_sentence1', \n",
    "                                                                         'p_sentence2', \n",
    "                                                                         sent_model, \n",
    "                                                                         preprocess_type='preprocess')\n",
    "\n",
    "\n",
    "del sent_model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c03caa0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.754 0.909 0.824\n",
      "0.752 0.91 0.823\n",
      "0.757 0.908 0.826\n"
     ]
    }
   ],
   "source": [
    "print(precision, recall, f1_score)\n",
    "print(b_precision, b_recall, b_f1_score)\n",
    "print(p_precision, p_recall, p_f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e7aebf",
   "metadata": {},
   "source": [
    "#### 4.2.2 Stsb-roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27e4f983",
   "metadata": {},
   "outputs": [],
   "source": [
    "stsb_roberta_df = sts_dev_test_updated.copy()\n",
    "\n",
    "sent_model = get_sent_model('sentence-transformers/stsb-roberta-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ed516c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, f1_score, updated_df = call_sent_transformers(stsb_roberta_df, 'sentence1', \n",
    "                                                                 'sentence2', \n",
    "                                                                 sent_model, preprocess_type=None)\n",
    "\n",
    "b_precision, b_recall, b_f1_score, b_updated_df = call_sent_transformers(stsb_roberta_df, 'b_sentence1', \n",
    "                                                                         'b_sentence2', \n",
    "                                                                         sent_model, preprocess_type='basic')\n",
    "\n",
    "p_precision, p_recall, p_f1_score, p_updated_df = call_sent_transformers(stsb_roberta_df, 'p_sentence1', \n",
    "                                                                         'p_sentence2', \n",
    "                                                                         sent_model, \n",
    "                                                                         preprocess_type='preprocess')\n",
    "\n",
    "\n",
    "del sent_model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48ac6607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.784 0.899 0.838\n",
      "0.782 0.902 0.838\n",
      "0.784 0.888 0.832\n"
     ]
    }
   ],
   "source": [
    "print(precision, recall, f1_score)\n",
    "print(b_precision, b_recall, b_f1_score)\n",
    "print(p_precision, p_recall, p_f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2e1c6a",
   "metadata": {},
   "source": [
    "#### 4.3 BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a37c3725",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bert_results(df, columnA, columnB, model, tokenizer, CLS_embedding, preprocess_type):\n",
    "    \n",
    "        ref_sent1 = df[columnA].tolist()\n",
    "        ref_sent2 = df[columnB].tolist()\n",
    "        \n",
    "        ref_sent1 = [preprocessor.lowercase_str(x) for x in ref_sent1]\n",
    "        ref_sent2 = [preprocessor.lowercase_str(x) for x in ref_sent2]\n",
    "        \n",
    "        encoded_input1 = tokenizer(ref_sent1, padding=True, \n",
    "                                   truncation=True, \n",
    "                                   return_tensors=\"pt\")\n",
    "        \n",
    "        encoded_input2 = tokenizer(ref_sent2, padding=True, \n",
    "                                   truncation=True, \n",
    "                                   return_tensors=\"pt\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            sent_embeddings1 = model(**encoded_input1)\n",
    "            sent_embeddings2 = model(**encoded_input2)\n",
    "            \n",
    "        if CLS_embedding:\n",
    "            embedds1 = sent_embeddings1.last_hidden_state[:, 0, :]\n",
    "            embedds2 = sent_embeddings2.last_hidden_state[:, 0, :]\n",
    "            \n",
    "        else:\n",
    "            embedds1 = sent_embeddings1.last_hidden_state.mean(dim=1)\n",
    "            embedds2 = sent_embeddings2.last_hidden_state.mean(dim=1)\n",
    "            \n",
    "        norm_embeddings1 = torch.nn.functional.normalize(embedds1, p=2, dim=1).numpy()\n",
    "        norm_embeddings2 = torch.nn.functional.normalize(embedds2, p=2, dim=1).numpy()\n",
    "\n",
    "        cosine_scores = cosine_similarity(norm_embeddings1, norm_embeddings2)\n",
    "        \n",
    "        updated_df = get_prediction_values(cosine_scores, df, preprocess_type)\n",
    "\n",
    "        precision, recall, f1_score = evaluate_predictions(updated_df)\n",
    "\n",
    "        return precision, recall, f1_score, updated_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c70e2768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b305811d791946078fc7035bf025e14c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"bert-base-uncased\"\n",
    "\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "bert_model = BertModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0516d12c",
   "metadata": {},
   "source": [
    "#### 4.3.1 bert avg. embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f5d10395",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_avg_df = sts_dev_test_updated.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b1ef308",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, f1_score, updated_df = get_bert_results(bert_avg_df, 'sentence1', 'sentence2', \n",
    "                                                          bert_model, bert_tokenizer, CLS_embedding=False,\n",
    "                                                          preprocess_type= None)\n",
    "\n",
    "bprecision, brecall, bf1_score, bupdated_df = get_bert_results(bert_avg_df, 'b_sentence1', 'b_sentence2', \n",
    "                                                           bert_model, bert_tokenizer, CLS_embedding=False,\n",
    "                                                              preprocess_type = 'basic')\n",
    "\n",
    "\n",
    "pprecision, precall, pf1_score, pupdated_df = get_bert_results(bert_avg_df, 'p_sentence1', 'p_sentence2', \n",
    "                                                            bert_model, bert_tokenizer, CLS_embedding=False,\n",
    "                                                              preprocess_type='preprocess')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60819da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.778 0.77 0.774\n",
      "0.775 0.768 0.772\n",
      "0.784 0.745 0.764\n"
     ]
    }
   ],
   "source": [
    "print(precision, recall, f1_score)\n",
    "print(bprecision, brecall, bf1_score)\n",
    "print(pprecision, precall, pf1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b838b81",
   "metadata": {},
   "source": [
    "#### 4.3.2 bert CLS embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7e5c74fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_cls_df = sts_dev_test_updated.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2af37821",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, f1_score, updated_df = get_bert_results(bert_cls_df, 'sentence1', 'sentence2', \n",
    "                                                          bert_model, bert_tokenizer, CLS_embedding=True,\n",
    "                                                           preprocess_type= None)\n",
    "\n",
    "bprecision, brecall, bf1_score, bupdated_df = get_bert_results(bert_cls_df, 'b_sentence1', 'b_sentence2', \n",
    "                                                               bert_model, bert_tokenizer, CLS_embedding=True,\n",
    "                                                               preprocess_type= 'basic')\n",
    "\n",
    "\n",
    "pprecision, precall, pf1_score, pupdated_df = get_bert_results(bert_cls_df, 'p_sentence1', 'p_sentence2', \n",
    "                                                               bert_model, bert_tokenizer, CLS_embedding=True,\n",
    "                                                               preprocess_type= 'preprocess')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ab8e68b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.785 0.573 0.662\n",
      "0.783 0.593 0.675\n",
      "0.814 0.591 0.685\n"
     ]
    }
   ],
   "source": [
    "print(precision, recall, f1_score)\n",
    "print(bprecision, brecall, bf1_score)\n",
    "print(pprecision, precall, pf1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d0b931be",
   "metadata": {},
   "outputs": [],
   "source": [
    "del bert_model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
