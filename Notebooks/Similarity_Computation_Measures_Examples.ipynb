{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d4ba5b8",
   "metadata": {},
   "source": [
    "### Description\n",
    "\n",
    "The notebook serves as an educational guide for understanding and applying different similarity metrics to textual data, with a specific emphasis on comparing requirement texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fbedf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "from scipy.spatial.distance import jaccard, dice\n",
    "import numpy as np\n",
    "from Levenshtein import distance as levenshtein_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5234065f",
   "metadata": {},
   "outputs": [],
   "source": [
    "REQ1 = \"The train must automatically signal its arrival when it is 500 meters from the station.\"\n",
    "REQ2 = \"A train should signal its approach automatically as it reaches within 500 meters of a station.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f735db",
   "metadata": {},
   "source": [
    "##### [Note] Similarity Metrics functions can be implemented in python or by just importing functions from readily available packages like scipy or sklearn. Both methods are mentioned below!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49157570",
   "metadata": {},
   "source": [
    "#### [Note] For vector-based similarity metrics, we use a simple bag-of-words representation model for vectorization. Most sophisticated models  like TFIDF word embeddings could yeild better results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b50d39",
   "metadata": {},
   "source": [
    "##### Dice & JSI can be calculated based on string- or vector-level representation.\n",
    "\n",
    "[Note] The difference in results arises from what is being compared: At string-level, the sequences are compared directly at a granular level, such as n grams within the requirements. At binary vector level, the calculation is based on presence or absence of the features. This is useful high-dimensional sparse data. Both of the methods are mentioned below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10340df1",
   "metadata": {},
   "source": [
    "### 1. DICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "310255ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dice Coefficient: 0.5161290322580645\n"
     ]
    }
   ],
   "source": [
    "# At string level\n",
    "\n",
    "def dice_coefficient(req_a, req_b):\n",
    "    # Same as Jaccard, but normalized for set size\n",
    "    req_a_set = set(req_a.split())\n",
    "    req_b_set = set(req_b.split())\n",
    "    intersection = req_a_set & req_b_set\n",
    "    return 2 * len(intersection) / (len(req_a_set) + len(req_b_set))\n",
    "\n",
    "print(f\"Dice Coefficient: {dice_coefficient(REQ1, REQ2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5623e2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dice Coefficient: 0.5714285714285714\n"
     ]
    }
   ],
   "source": [
    "# At binary-vectors level\n",
    "\n",
    "vectorizer = CountVectorizer().fit_transform([REQ1, REQ2])\n",
    "vectors = vectorizer.toarray()\n",
    "\n",
    "binary_vectors = np.where(vectors > 0, 1, 0)\n",
    "dice_sim = 1 - dice(binary_vectors[0], binary_vectors[1])\n",
    "print(f\"Dice Coefficient: {dice_sim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da62191",
   "metadata": {},
   "source": [
    "### 2. JSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fa3e5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard Similarity Index: 0.34782608695652173\n"
     ]
    }
   ],
   "source": [
    "# at string-level\n",
    "def jaccard_similarity(req_a, req_b):\n",
    "    # Represent requirements as sets of unique words/terms\n",
    "    req_a_set = set(req_a.split())\n",
    "    req_b_set = set(req_b.split())\n",
    "    intersection = req_a_set & req_b_set\n",
    "    union = req_a_set | req_b_set\n",
    "    return len(intersection) / len(union)\n",
    "\n",
    "print(f\"Jaccard Similarity Index: {jaccard_similarity(REQ1, REQ2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "412b7cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard Similarity Index: 0.4\n"
     ]
    }
   ],
   "source": [
    "# at binary-vectorizer level\n",
    "vectorizer = CountVectorizer().fit_transform([REQ1, REQ2])\n",
    "vectors = vectorizer.toarray()\n",
    "\n",
    "binary_vectors = np.where(vectors > 0, 1, 0)\n",
    "jaccard_sim = 1 - jaccard(binary_vectors[0], binary_vectors[1])\n",
    "print(f\"Jaccard Similarity Index: {jaccard_sim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914e0751",
   "metadata": {},
   "source": [
    "### 3. Edit distance (levenshtein)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6f9ddb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# string-level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcc4e7f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def levenshtein_distance(req_a, req_b):\n",
    "    dp = np.zeros((len(req_a) + 1, len(req_b) + 1))\n",
    "\n",
    "    # Initialize base cases\n",
    "    for i in range(len(req_a) + 1):\n",
    "        dp[i, 0] = i  # Deletion cost to transform req_a into empty string\n",
    "    for j in range(len(req_b) + 1):\n",
    "        dp[0, j] = j  # Insertion cost to transform req_b into empty string\n",
    "\n",
    "    # Fill the DP table\n",
    "    for i in range(1, len(req_a) + 1):\n",
    "        for j in range(1, len(req_b) + 1):\n",
    "            if req_a[i - 1] == req_b[j - 1]:\n",
    "                cost = 0  # No cost if characters are the same\n",
    "            else:\n",
    "                cost = 1  # Substitution cost\n",
    "            dp[i, j] = min(\n",
    "                dp[i - 1, j] + 1,  # Deletion from req_a\n",
    "                dp[i, j - 1] + 1,  # Insertion into req_a\n",
    "                dp[i - 1, j - 1] + cost  # Substitution or deletion/insertion combo\n",
    "            )\n",
    "\n",
    "    return dp[len(req_a), len(req_b)]\n",
    "\n",
    "levenshtein_distance(REQ1, REQ2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561fd236",
   "metadata": {},
   "source": [
    "##### OR: You can also calculate with just scipy package calling levenshtein_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad21f81a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edit Distance: 49.0\n"
     ]
    }
   ],
   "source": [
    "edit_dist = levenshtein_distance(REQ1, REQ2)\n",
    "print(f\"Edit Distance: {edit_dist}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4890dbfc",
   "metadata": {},
   "source": [
    "### 4. Euclidean Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "300e7391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector-level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31505763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean Distance: 3.872983346207417\n"
     ]
    }
   ],
   "source": [
    "def euclidean_distance(req_a, req_b):\n",
    "    # Vectorize requirements and calculate distance\n",
    "    vectorizer = CountVectorizer().fit_transform([REQ1, REQ2])\n",
    "    vectors = vectorizer.toarray()\n",
    "    \n",
    "    return np.linalg.norm(vectors[0] - vectors[1])\n",
    "\n",
    "print(f\"Euclidean Distance: {euclidean_distance(REQ1, REQ2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3066ffb",
   "metadata": {},
   "source": [
    "##### OR: You can also calculate with just scipy package calling euclidean_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f009f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean Distance: 3.872983346207417\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer().fit_transform([REQ1, REQ2])\n",
    "vectors = vectorizer.toarray()\n",
    "euc_dist = euclidean_distances([vectors[0]], [vectors[1]])[0][0]\n",
    "\n",
    "print(f\"Euclidean Distance: {euc_dist}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd676a14",
   "metadata": {},
   "source": [
    "### 5. Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e67b12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.5185629788417315\n"
     ]
    }
   ],
   "source": [
    "def cosine_similarity(req_a, req_b):\n",
    "    \n",
    "    vectorizer = CountVectorizer().fit_transform([REQ1, REQ2])\n",
    "    vectors = vectorizer.toarray()\n",
    "    \n",
    "    req_a_vec = vectors[0]\n",
    "    req_b_vec = vectors[1]\n",
    "    dot_product = np.dot(req_a_vec, req_b_vec)\n",
    "    \n",
    "    mag_a = np.linalg.norm(req_a_vec)\n",
    "    mag_b = np.linalg.norm(req_b_vec)\n",
    "    \n",
    "    return dot_product / (mag_a * mag_b)\n",
    "\n",
    "print(f\"Cosine Similarity: {cosine_similarity(REQ1, REQ2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1631b2e",
   "metadata": {},
   "source": [
    "##### OR: You can also calculate with just sklearn package calling cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6285f6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.5185629788417315\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer().fit_transform([REQ1, REQ2])\n",
    "vectors = vectorizer.toarray()\n",
    "# [Read More at:] https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_similarity.html\n",
    "cos_sim = cosine_similarity([vectors[0]], [vectors[1]])\n",
    "print(f\"Cosine Similarity: {cos_sim}\")                                                 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.8 (demos)",
   "language": "python",
   "name": "demos"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
